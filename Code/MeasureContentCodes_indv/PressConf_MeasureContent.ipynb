{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNsbYTVXpHgXb4IjrXAzj5w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import re\n","import json\n","import random\n","import time\n","\n","# Set random seed for reproducibility\n","seed = int(time.time())\n","random.seed(seed)\n","np.random.seed(seed)\n","\n","# Directory paths\n","dict_dir = '/content/drive/MyDrive/FedComs/Dictionaries'\n","input_file = '/content/drive/MyDrive/FedComs/PressConf/fomc_press_conferences.csv'\n","validation_output_dir = '/content/drive/MyDrive/FedComs/Validation_Sets'\n","summary_output_dir = '/content/drive/MyDrive/FedComs/PressConf'\n","\n","# Create output directories if they don't exist\n","for directory in [validation_output_dir, summary_output_dir]:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","os.chdir(summary_output_dir)\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","# ============================================================================\n","# STEP 1: LOAD DICTIONARIES\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"LOADING DICTIONARIES\")\n","print(\"=\"*70)\n","\n","with open(os.path.join(dict_dir, 'labor_indicators.json'), 'r') as f:\n","    LABOR_INDICATORS = json.load(f)\n","\n","with open(os.path.join(dict_dir, 'inflation_indicators.json'), 'r') as f:\n","    INFLATION_INDICATORS = json.load(f)\n","\n","with open(os.path.join(dict_dir, 'inflation_pattern_mapping.json'), 'r') as f:\n","    INFLATION_PATTERN_TO_INDICATOR = json.load(f)\n","\n","print(\"Dictionaries loaded successfully!\")\n","print(f\"Labor indicators: {list(LABOR_INDICATORS.keys())}\")\n","print(f\"Inflation categories: {list(INFLATION_INDICATORS.keys())}\")\n","\n","# ============================================================================\n","# STEP 2: TEXT PROCESSING FUNCTIONS\n","# ============================================================================\n","\n","def fix_text_encoding(text):\n","    \"\"\"Fix common text encoding issues.\"\"\"\n","    text = text.replace('â€\"', '—')\n","    text = text.replace('â€\"', '—')\n","    text = text.replace('â€œ', '\"')\n","    text = text.replace('â€', '\"')\n","    text = text.replace('\\u2013', '–')\n","    text = text.replace('\\u2014', '—')\n","    text = text.replace('\\u2018', \"'\")\n","    text = text.replace('\\u2019', \"'\")\n","    text = text.replace('\\u201c', '\"')\n","    text = text.replace('\\u201d', '\"')\n","    text = text.replace('\\u2026', '...')\n","    text = re.sub(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f\\x7f-\\x9f]', '', text)\n","    return text\n","\n","def split_into_sentences(text):\n","    \"\"\"Split text into sentences, preserving initials and abbreviations.\"\"\"\n","    text = fix_text_encoding(text)\n","\n","    abbreviations = [\n","        r'\\bU\\.S\\.A\\.', r'\\bU\\.S\\.', r'\\bU\\.K\\.', r'\\bE\\.U\\.',\n","        r'\\bSt\\.', r'\\bMr\\.', r'\\bMrs\\.', r'\\bMs\\.', r'\\bDr\\.',\n","        r'\\bProf\\.', r'\\bSr\\.', r'\\bJr\\.', r'\\bvs\\.', r'\\betc\\.',\n","        r'\\bi\\.e\\.', r'\\be\\.g\\.', r'\\bVol\\.', r'\\bNo\\.', r'\\bpp\\.',\n","        r'\\bCo\\.', r'\\bInc\\.', r'\\bLtd\\.', r'\\bCorp\\.',\n","        r'\\bPh\\.D\\.', r'\\bM\\.A\\.', r'\\bM\\.S\\.', r'\\bB\\.A\\.',\n","        r'\\bD\\.C\\.', r'\\bA\\.M\\.', r'\\bP\\.M\\.'\n","    ]\n","\n","    for idx, abbr in enumerate(abbreviations):\n","        text = re.sub(abbr, f'<ABBR_{idx}>', text, flags=re.IGNORECASE)\n","\n","    text = re.sub(r'\\b([A-Z])\\.(\\s+[A-Z]\\.)*(?=\\s+[A-Z][a-z]+)', lambda m: m.group(0).replace('.', f'<NAME>'), text)\n","    text = re.sub(r'\\b\\d+\\.\\d+\\b', lambda m: m.group(0).replace('.', '<DEC>'), text)\n","\n","    voting_pattern = r'((?:Voting for|Voting against)\\s+[^.!?]+?)([.!?]+\\s+|$)'\n","    voting_matches = []\n","    def store_voting_match(match):\n","        voting_matches.append(match.group(1))\n","        return f'<VOTE_{len(voting_matches) - 1}>'\n","    text = re.sub(voting_pattern, store_voting_match, text)\n","\n","    sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z]|$)', text)\n","    sentences = [s.strip() for s in sentences if s.strip()]\n","\n","    restored_sentences = []\n","    for sentence in sentences:\n","        for idx in range(len(abbreviations)):\n","            sentence = sentence.replace(f'<ABBR_{idx}>', abbreviations[idx].replace(r'\\b', '').replace(r'\\.', '.'))\n","        sentence = sentence.replace('<NAME>', '.')\n","        sentence = sentence.replace('<DEC>', '.')\n","        for i, voting_list in enumerate(voting_matches):\n","            placeholder = f'<VOTE_{i}>'\n","            if placeholder in sentence:\n","                sentence = sentence.replace(placeholder, voting_list)\n","        restored_sentences.append(sentence)\n","\n","    return restored_sentences\n","\n","# ============================================================================\n","# STEP 3: CLASSIFICATION FUNCTIONS\n","# ============================================================================\n","\n","def check_keywords_in_sentence(sentence, keywords):\n","    \"\"\"Check if any keyword appears in the sentence.\"\"\"\n","    sentence_lower = sentence.lower()\n","    for keyword in keywords:\n","        pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n","        if re.search(pattern, sentence_lower):\n","            return True\n","    return False\n","\n","def check_employment_indicator(sentence, keywords):\n","    \"\"\"Check for Employment indicator, excluding maximum/full employment.\"\"\"\n","    sentence_lower = sentence.lower()\n","\n","    # Check if sentence contains maximum employment, full employment, or employment goal\n","    if re.search(r'\\b(?:maximum|full)\\s+employment\\b', sentence_lower):\n","        return False\n","    if re.search(r'\\bemployment\\s+goal\\b', sentence_lower):\n","        return False\n","\n","    # Otherwise check for employment keywords normally\n","    for keyword in keywords:\n","        pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n","        if re.search(pattern, sentence_lower):\n","            return True\n","    return False\n","\n","def check_general_labor_term(sentence):\n","    \"\"\"Check if sentence contains general labor terms (from General Labor category).\"\"\"\n","    sentence_lower = sentence.lower()\n","    general_labor_keywords = LABOR_INDICATORS.get(\"General Labor\", [])\n","    for keyword in general_labor_keywords:\n","        pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n","        if re.search(pattern, sentence_lower):\n","            return True\n","    return False\n","\n","def check_general_inflation_terms(sentence):\n","    \"\"\"Check if sentence contains general inflation terms (from General Inflation category).\"\"\"\n","    sentence_lower = sentence.lower()\n","    general_inflation_patterns = INFLATION_INDICATORS.get(\"General Inflation\", {}).get(\"general_patterns\", [])\n","    for pattern in general_inflation_patterns:\n","        if re.search(pattern, sentence_lower, re.IGNORECASE):\n","            return True\n","    return False\n","\n","def check_inflation_sentence(sentence):\n","    \"\"\"Check if sentence mentions any inflation indicator.\"\"\"\n","    mentioned_indicators = set()\n","    sentence_lower = sentence.lower()\n","\n","    for category, subcategories in INFLATION_INDICATORS.items():\n","        for pattern_name, pattern_list in subcategories.items():\n","            for pattern in pattern_list:\n","                if re.search(pattern, sentence_lower, re.IGNORECASE):\n","                    indicator_name = INFLATION_PATTERN_TO_INDICATOR.get(pattern_name, \"Other\")\n","                    mentioned_indicators.add(indicator_name)\n","                    break\n","\n","    # If sentence has both Core_CPI and Core, remove the generic Core\n","    if \"Core_CPI\" in mentioned_indicators and \"Core\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Core\")\n","\n","    # If sentence has both Core_PCE and Core, remove the generic Core\n","    if \"Core_PCE\" in mentioned_indicators and \"Core\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Core\")\n","\n","    # If sentence has both Headline_CPI and Headline, remove the generic Headline\n","    if \"Headline_CPI\" in mentioned_indicators and \"Headline\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Headline\")\n","\n","    # If sentence has both Headline_PCE and Headline, remove the generic Headline\n","    if \"Headline_PCE\" in mentioned_indicators and \"Headline\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Headline\")\n","\n","    # If sentence has Core_PCE, remove Headline_PCE (since \"core pce\" shouldn't match headline)\n","    if \"Core_PCE\" in mentioned_indicators and \"Headline_PCE\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Headline_PCE\")\n","\n","    # If sentence has Core_CPI, remove Headline_CPI (since \"core cpi\" shouldn't match headline)\n","    if \"Core_CPI\" in mentioned_indicators and \"Headline_CPI\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Headline_CPI\")\n","\n","    return mentioned_indicators\n","\n","def classify_sentence(sentence):\n","    \"\"\"Classify a single sentence and return its indicators.\"\"\"\n","    labor_specific_found = False\n","    labor_indicators_in_sentence = set()\n","\n","    # Check all labor indicators EXCEPT \"General Labor\"\n","    for indicator, keywords in LABOR_INDICATORS.items():\n","        if indicator == \"General Labor\":\n","            continue  # Skip general labor for indicator counts\n","\n","        # Use special handling for Employment indicator\n","        if indicator == \"Employment\":\n","            if check_employment_indicator(sentence, keywords):\n","                labor_indicators_in_sentence.add(indicator)\n","                labor_specific_found = True\n","        else:\n","            if check_keywords_in_sentence(sentence, keywords):\n","                labor_indicators_in_sentence.add(indicator)\n","                labor_specific_found = True\n","\n","    labor_general_found = check_general_labor_term(sentence)\n","    labor_found = labor_specific_found or labor_general_found\n","\n","    inflation_indicators_in_sentence = check_inflation_sentence(sentence)\n","    inflation_specific_found = bool(inflation_indicators_in_sentence)\n","\n","    inflation_general_found = check_general_inflation_terms(sentence)\n","    inflation_found = inflation_specific_found or inflation_general_found\n","\n","    if labor_found and inflation_found:\n","        classification = \"Both\"\n","    elif labor_found:\n","        classification = \"Labor\"\n","    elif inflation_found:\n","        classification = \"Inflation\"\n","    else:\n","        classification = \"Neither\"\n","\n","    return {\n","        'classification': classification,\n","        'labor_indicators': list(labor_indicators_in_sentence),\n","        'inflation_indicators': list(inflation_indicators_in_sentence)\n","    }\n","\n","def analyze_transcript(text):\n","    \"\"\"Analyze a single transcript for labor and inflation content.\"\"\"\n","    sentences = split_into_sentences(text)\n","    total_sentences = len(sentences)\n","\n","    labor_sentences = 0\n","    inflation_sentences = 0\n","    both_sentences = 0\n","\n","    # Only create indicator counts for non-general categories\n","    labor_indicator_counts = {indicator: 0 for indicator in LABOR_INDICATORS.keys() if indicator != \"General Labor\"}\n","    inflation_indicator_list = sorted(list(set(\n","        indicator for indicator in INFLATION_PATTERN_TO_INDICATOR.values()\n","        if indicator not in [\"General_Inflation\", \"Other\"]\n","    )))\n","    inflation_indicator_counts = {indicator: 0 for indicator in inflation_indicator_list}\n","\n","    sentence_data_list = []\n","\n","    for sent_idx, sentence in enumerate(sentences):\n","        classification_result = classify_sentence(sentence)\n","\n","        # Filter out general categories from the indicator lists\n","        labor_indicators_filtered = [ind for ind in classification_result['labor_indicators']\n","                                      if ind != \"General Labor\"]\n","        inflation_indicators_filtered = [ind for ind in classification_result['inflation_indicators']\n","                                          if ind not in [\"General_Inflation\", \"Other\"]]\n","\n","        sentence_data = {\n","            'sentence_number': sent_idx + 1,\n","            'sentence_text': sentence,\n","            'classification': classification_result['classification'],\n","            'labor_indicators': ', '.join(sorted(labor_indicators_filtered)) if labor_indicators_filtered else '',\n","            'inflation_indicators': ', '.join(sorted(inflation_indicators_filtered)) if inflation_indicators_filtered else ''\n","        }\n","        sentence_data_list.append(sentence_data)\n","\n","        labor_specific_found = bool(classification_result['labor_indicators'])\n","        labor_general_found = check_general_labor_term(sentence)\n","        labor_found = labor_specific_found or labor_general_found\n","\n","        inflation_specific_found = bool(classification_result['inflation_indicators'])\n","        inflation_general_found = check_general_inflation_terms(sentence)\n","        inflation_found = inflation_specific_found or inflation_general_found\n","\n","        if labor_found and inflation_found:\n","            both_sentences += 1\n","            labor_sentences += 1\n","            inflation_sentences += 1\n","        elif labor_found:\n","            labor_sentences += 1\n","        elif inflation_found:\n","            inflation_sentences += 1\n","\n","        # Only count specific indicators (not general terms or \"Other\") for emphasis vectors\n","        for indicator in classification_result['labor_indicators']:\n","            if indicator in labor_indicator_counts:\n","                labor_indicator_counts[indicator] += 1\n","\n","        for indicator in classification_result['inflation_indicators']:\n","            if indicator in inflation_indicator_counts:\n","                inflation_indicator_counts[indicator] += 1\n","\n","    total_labor_mentions = sum(labor_indicator_counts.values())\n","    total_inflation_mentions = sum(inflation_indicator_counts.values())\n","\n","    labor_emphasis = {}\n","    for indicator, count in labor_indicator_counts.items():\n","        labor_emphasis[f\"labor_emphasis_{indicator}\"] = count / total_labor_mentions if total_labor_mentions > 0 else 0\n","\n","    inflation_emphasis = {}\n","    for indicator, count in inflation_indicator_counts.items():\n","        inflation_emphasis[f\"inflation_emphasis_{indicator}\"] = count / total_inflation_mentions if total_inflation_mentions > 0 else 0\n","\n","    labor_sentence_share = {}\n","    for indicator, count in labor_indicator_counts.items():\n","        labor_sentence_share[f\"labor_share_total_sentences_{indicator}\"] = count / total_sentences if total_sentences > 0 else 0\n","\n","    inflation_sentence_share = {}\n","    for indicator, count in inflation_indicator_counts.items():\n","        inflation_sentence_share[f\"inflation_share_total_sentences_{indicator}\"] = count / total_sentences if total_sentences > 0 else 0\n","\n","    labor_inflation_total = labor_sentences + inflation_sentences - both_sentences\n","    labor_share_of_labor_inflation = labor_sentences / labor_inflation_total if labor_inflation_total > 0 else 0\n","\n","    summary_results = {\n","        'sentences_on_labor': labor_sentences,\n","        'sentences_on_inflation': inflation_sentences,\n","        'sentences_on_both': both_sentences,\n","        'total_sentences': total_sentences,\n","        'labor_share_of_labor_inflation_sentences': labor_share_of_labor_inflation\n","    }\n","\n","    for indicator, count in labor_indicator_counts.items():\n","        summary_results[f'labor_{indicator}_count'] = count\n","\n","    for indicator, count in inflation_indicator_counts.items():\n","        summary_results[f'inflation_{indicator}_count'] = count\n","\n","    summary_results.update(labor_emphasis)\n","    summary_results.update(inflation_emphasis)\n","    summary_results.update(labor_sentence_share)\n","    summary_results.update(inflation_sentence_share)\n","\n","    return summary_results, sentence_data_list\n","\n","# ============================================================================\n","# STEP 4: PROCESS PRESS CONFERENCES\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"CLASSIFYING PRESS CONFERENCE CONTENT\")\n","print(\"=\"*70)\n","\n","# Read the press conference file\n","print(f\"Reading from: {input_file}\")\n","try:\n","    df = pd.read_csv(input_file, encoding='utf-8', encoding_errors='replace')\n","    print(f\"Loaded {len(df)} records from press conference file\")\n","    print(f\"Columns: {df.columns.tolist()}\")\n","    print(f\"Speaker distribution:\\n{df['speaker'].value_counts()}\")\n","except Exception as e:\n","    print(f\"Error reading press conference file: {e}\")\n","    exit()\n","\n","results_list = []\n","all_sentences = []\n","\n","# Group by date to process both speakers together\n","grouped = df.groupby('date')\n","print(f\"\\nProcessing {len(grouped)} press conferences...\")\n","\n","for date, group in grouped:\n","    if len(results_list) % 10 == 0:\n","        print(f\"Processing conference {len(results_list)//2 + 1}/{len(grouped)}: {date}\")\n","\n","    # Process each speaker\n","    for idx, row in group.iterrows():\n","        speaker = row['speaker']\n","        text = str(row['text']) if pd.notna(row['text']) else ''\n","\n","        if len(text.strip()) == 0:\n","            print(f\"  Warning: Empty text for {date}, speaker {speaker}\")\n","            continue\n","\n","        try:\n","            summary_results, sentence_data_list = analyze_transcript(text)\n","\n","            # Add metadata\n","            summary_results['press_conf_id'] = str(row['id']) if 'id' in row else f\"{date}_{speaker}\"\n","            summary_results['date'] = date\n","            summary_results['speaker'] = speaker\n","            summary_results['source_url'] = str(row['source_url']) if 'source_url' in row else ''\n","\n","            results_list.append(summary_results)\n","\n","            # Add sentence-level data\n","            for sentence_data in sentence_data_list:\n","                sentence_data['press_conf_id'] = summary_results['press_conf_id']\n","                sentence_data['date'] = date\n","                sentence_data['speaker'] = speaker\n","                all_sentences.append(sentence_data)\n","\n","        except Exception as e:\n","            print(f\"  Error processing {date}, speaker {speaker}: {e}\")\n","            import traceback\n","            print(f\"  Full traceback: {traceback.format_exc()}\")\n","            continue\n","\n","# ============================================================================\n","# STEP 5: SAVE RESULTS\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"SAVING RESULTS\")\n","print(\"=\"*70)\n","\n","# Create summary dataframe\n","results_df = pd.DataFrame(results_list)\n","\n","if len(results_df) > 0:\n","    cols = ['press_conf_id', 'date', 'speaker', 'source_url'] + [col for col in results_df.columns\n","                                                                   if col not in ['press_conf_id', 'date', 'speaker', 'source_url']]\n","    results_df = results_df[[col for col in cols if col in results_df.columns]]\n","    results_df = results_df.sort_values('date')\n","\n","    summary_output_file = os.path.join(summary_output_dir, 'press_conferences_content.csv')\n","    results_df.to_csv(summary_output_file, index=False)\n","    print(f\"\\nSummary dataset saved to: {summary_output_file}\")\n","    print(f\"Shape: {results_df.shape}\")\n","else:\n","    print(\"\\nWarning: No results to save!\")\n","\n","# Create sentence-level dataframe\n","sentences_df = pd.DataFrame(all_sentences)\n","\n","if len(sentences_df) > 0:\n","    print(f\"\\nTotal sentences extracted: {len(sentences_df)}\")\n","    print(\"\\nClassification distribution:\")\n","    print(sentences_df['classification'].value_counts())\n","\n","    # Sample sentences for validation\n","    n_labor = 15\n","    n_inflation = 15\n","    n_both = 5\n","    n_neither = 10\n","\n","    print(f\"\\nSampling sentences for validation...\")\n","    validation_samples = []\n","\n","    labor_sentences = sentences_df[sentences_df['classification'] == 'Labor']\n","    if len(labor_sentences) >= n_labor:\n","        validation_samples.append(labor_sentences.sample(n=n_labor, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(labor_sentences)} labor sentences available\")\n","        validation_samples.append(labor_sentences)\n","\n","    inflation_sentences = sentences_df[sentences_df['classification'] == 'Inflation']\n","    if len(inflation_sentences) >= n_inflation:\n","        validation_samples.append(inflation_sentences.sample(n=n_inflation, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(inflation_sentences)} inflation sentences available\")\n","        validation_samples.append(inflation_sentences)\n","\n","    both_sentences = sentences_df[sentences_df['classification'] == 'Both']\n","    if len(both_sentences) >= n_both:\n","        validation_samples.append(both_sentences.sample(n=n_both, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(both_sentences)} both sentences available\")\n","        validation_samples.append(both_sentences)\n","\n","    neither_sentences = sentences_df[sentences_df['classification'] == 'Neither']\n","    if len(neither_sentences) >= n_neither:\n","        validation_samples.append(neither_sentences.sample(n=n_neither, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(neither_sentences)} neither sentences available\")\n","        validation_samples.append(neither_sentences)\n","\n","    validation_df = pd.concat(validation_samples, ignore_index=True)\n","    validation_df = validation_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n","\n","    validation_output_file = os.path.join(validation_output_dir, 'press_conferences_validate.csv')\n","    validation_df.to_csv(validation_output_file, index=False)\n","\n","    print(f\"\\nValidation set created: {validation_output_file}\")\n","    print(f\"Total sentences in validation set: {len(validation_df)}\")\n","    print(f\"\\nValidation set distribution:\")\n","    print(validation_df['classification'].value_counts())\n","\n","# ============================================================================\n","# STEP 6: PRINT SUMMARY STATISTICS\n","# ============================================================================\n","\n","if len(results_df) > 0:\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"SUMMARY STATISTICS\")\n","    print(\"=\"*70)\n","    print(f\"\\nNumber of press conference speakers analyzed: {len(results_df)}\")\n","\n","    # Overall statistics\n","    print(f\"\\nAverage sentences per speaker: {results_df['total_sentences'].mean():.1f}\")\n","    print(f\"Average labor sentences: {results_df['sentences_on_labor'].mean():.1f}\")\n","    print(f\"Average inflation sentences: {results_df['sentences_on_inflation'].mean():.1f}\")\n","    print(f\"Average sentences on both: {results_df['sentences_on_both'].mean():.1f}\")\n","    print(f\"Average labor share of labor/inflation: {results_df['labor_share_of_labor_inflation_sentences'].mean():.2%}\")\n","\n","    # Statistics by speaker type\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"STATISTICS BY SPEAKER TYPE\")\n","    print(\"-\"*70)\n","    for speaker in results_df['speaker'].unique():\n","        speaker_df = results_df[results_df['speaker'] == speaker]\n","        print(f\"\\n{speaker}:\")\n","        print(f\"  Count: {len(speaker_df)}\")\n","        print(f\"  Avg sentences: {speaker_df['total_sentences'].mean():.1f}\")\n","        print(f\"  Avg labor sentences: {speaker_df['sentences_on_labor'].mean():.1f}\")\n","        print(f\"  Avg inflation sentences: {speaker_df['sentences_on_inflation'].mean():.1f}\")\n","        print(f\"  Avg labor share: {speaker_df['labor_share_of_labor_inflation_sentences'].mean():.2%}\")\n","\n","    # Labor emphasis breakdown\n","    labor_emphasis_cols = [col for col in results_df.columns if col.startswith('labor_emphasis_')]\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"AVERAGE LABOR EMPHASIS VECTORS\")\n","    print(\"-\"*70)\n","    for col in sorted(labor_emphasis_cols):\n","        indicator_name = col.replace('labor_emphasis_', '')\n","        avg_emphasis = results_df[col].mean()\n","        print(f\"{indicator_name:20s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","    total_labor_emphasis = results_df[labor_emphasis_cols].mean().sum()\n","    print(f\"\\n{'Total':20s}: {total_labor_emphasis:.4f}\")\n","\n","    # Inflation emphasis breakdown\n","    inflation_emphasis_cols = [col for col in results_df.columns if col.startswith('inflation_emphasis_')]\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"AVERAGE INFLATION EMPHASIS VECTORS\")\n","    print(\"-\"*70)\n","    for col in sorted(inflation_emphasis_cols):\n","        indicator_name = col.replace('inflation_emphasis_', '')\n","        avg_emphasis = results_df[col].mean()\n","        print(f\"{indicator_name:20s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","    total_inflation_emphasis = results_df[inflation_emphasis_cols].mean().sum()\n","    print(f\"\\n{'Total':20s}: {total_inflation_emphasis:.4f}\")\n","\n","    # Compare chair vs other speakers\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"CHAIR VS OTHER SPEAKERS COMPARISON\")\n","    print(\"-\"*70)\n","\n","    chair_df = results_df[results_df['speaker'] != 'Other']\n","    other_df = results_df[results_df['speaker'] == 'Other']\n","\n","    if len(chair_df) > 0 and len(other_df) > 0:\n","        print(\"\\nLabor Share:\")\n","        print(f\"  Chair average: {chair_df['labor_share_of_labor_inflation_sentences'].mean():.2%}\")\n","        print(f\"  Other average: {other_df['labor_share_of_labor_inflation_sentences'].mean():.2%}\")\n","\n","        print(\"\\nTop 3 Labor Indicators (Chair):\")\n","        for col in sorted(labor_emphasis_cols, key=lambda x: chair_df[x].mean(), reverse=True)[:3]:\n","            indicator_name = col.replace('labor_emphasis_', '')\n","            print(f\"  {indicator_name:20s}: {chair_df[col].mean():.4f}\")\n","\n","        print(\"\\nTop 3 Labor Indicators (Other):\")\n","        for col in sorted(labor_emphasis_cols, key=lambda x: other_df[x].mean(), reverse=True)[:3]:\n","            indicator_name = col.replace('labor_emphasis_', '')\n","            print(f\"  {indicator_name:20s}: {other_df[col].mean():.4f}\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"PROCESSING COMPLETE!\")\n","print(\"=\"*70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c0sRYESnZzWr","executionInfo":{"status":"ok","timestamp":1759954293595,"user_tz":300,"elapsed":56536,"user":{"displayName":"Amanda Michaud","userId":"14525267344116117436"}},"outputId":"11558f63-011e-4b79-ba95-5f5fb4858da6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/FedComs/PressConf\n","\n","======================================================================\n","LOADING DICTIONARIES\n","======================================================================\n","Dictionaries loaded successfully!\n","Labor indicators: ['General Labor', 'Employment', 'Unemployment', 'Participation', 'Wages', 'Vacancies', 'Quits', 'Layoffs', 'Hiring']\n","Inflation categories: ['General Inflation', 'Core Measures', 'Headline Measures', 'Sectoral Measures', 'Producer Price Index', 'Wage Inflation', 'Inflation Expectations', 'Commodity Prices']\n","\n","======================================================================\n","CLASSIFYING PRESS CONFERENCE CONTENT\n","======================================================================\n","Reading from: /content/drive/MyDrive/FedComs/PressConf/fomc_press_conferences.csv\n","Loaded 170 records from press conference file\n","Columns: ['id', 'date', 'source_url', 'text', 'speaker']\n","Speaker distribution:\n","speaker\n","Other       85\n","Powell      57\n","Yellen      16\n","Bernanke    12\n","Name: count, dtype: int64\n","\n","Processing 85 press conferences...\n","Processing conference 1/85: 2011-04-27\n","Processing conference 6/85: 2012-06-20\n","Processing conference 11/85: 2013-09-18\n","Processing conference 16/85: 2014-12-17\n","Processing conference 21/85: 2016-03-16\n","Processing conference 26/85: 2017-06-14\n","Processing conference 31/85: 2018-09-26\n","Processing conference 36/85: 2019-06-19\n","Processing conference 41/85: 2020-01-29\n","Processing conference 46/85: 2020-09-16\n","Processing conference 51/85: 2021-04-28\n","Processing conference 56/85: 2021-12-15\n","Processing conference 61/85: 2022-07-27\n","Processing conference 66/85: 2023-03-22\n","Processing conference 71/85: 2023-11-01\n","Processing conference 76/85: 2024-06-12\n","Processing conference 81/85: 2025-01-29\n","\n","======================================================================\n","SAVING RESULTS\n","======================================================================\n","\n","Summary dataset saved to: /content/drive/MyDrive/FedComs/PressConf/press_conferences_content.csv\n","Shape: (170, 78)\n","\n","Total sentences extracted: 42525\n","\n","Classification distribution:\n","classification\n","Neither      36611\n","Labor         3723\n","Inflation     1602\n","Both           589\n","Name: count, dtype: int64\n","\n","Sampling sentences for validation...\n","\n","Validation set created: /content/drive/MyDrive/FedComs/Validation_Sets/press_conferences_validate.csv\n","Total sentences in validation set: 45\n","\n","Validation set distribution:\n","classification\n","Labor        15\n","Inflation    15\n","Neither      10\n","Both          5\n","Name: count, dtype: int64\n","\n","======================================================================\n","SUMMARY STATISTICS\n","======================================================================\n","\n","Number of press conference speakers analyzed: 170\n","\n","Average sentences per speaker: 250.1\n","Average labor sentences: 25.4\n","Average inflation sentences: 12.9\n","Average sentences on both: 3.5\n","Average labor share of labor/inflation: 72.18%\n","\n","----------------------------------------------------------------------\n","STATISTICS BY SPEAKER TYPE\n","----------------------------------------------------------------------\n","\n","Bernanke:\n","  Count: 12\n","  Avg sentences: 310.0\n","  Avg labor sentences: 44.7\n","  Avg inflation sentences: 22.6\n","  Avg labor share: 73.52%\n","\n","Other:\n","  Count: 85\n","  Avg sentences: 148.2\n","  Avg labor sentences: 7.6\n","  Avg inflation sentences: 4.0\n","  Avg labor share: 70.69%\n","\n","Yellen:\n","  Count: 16\n","  Avg sentences: 255.9\n","  Avg labor sentences: 41.6\n","  Avg inflation sentences: 22.9\n","  Avg labor share: 72.38%\n","\n","Powell:\n","  Count: 57\n","  Avg sentences: 388.0\n","  Avg labor sentences: 43.3\n","  Avg inflation sentences: 21.2\n","  Avg labor share: 74.07%\n","\n","----------------------------------------------------------------------\n","AVERAGE LABOR EMPHASIS VECTORS\n","----------------------------------------------------------------------\n","Employment          : 0.1102 (11.02%)\n","Hiring              : 0.1050 (10.50%)\n","Layoffs             : 0.0141 (1.41%)\n","Participation       : 0.1049 (10.49%)\n","Quits               : 0.0103 (1.03%)\n","Unemployment        : 0.3984 (39.84%)\n","Vacancies           : 0.0331 (3.31%)\n","Wages               : 0.2182 (21.82%)\n","\n","Total               : 0.9941\n","\n","----------------------------------------------------------------------\n","AVERAGE INFLATION EMPHASIS VECTORS\n","----------------------------------------------------------------------\n","Commodity_Prices    : 0.0831 (8.31%)\n","Core                : 0.0808 (8.08%)\n","Core_CPI            : 0.0065 (0.65%)\n","Core_PCE            : 0.0536 (5.36%)\n","Energy              : 0.0331 (3.31%)\n","Food                : 0.0056 (0.56%)\n","Goods               : 0.0183 (1.83%)\n","Headline            : 0.0304 (3.04%)\n","Headline_CPI        : 0.0567 (5.67%)\n","Headline_PCE        : 0.0553 (5.53%)\n","Housing             : 0.0232 (2.32%)\n","Inflation_Expectations: 0.3002 (30.02%)\n","PPI                 : 0.0037 (0.37%)\n","Services            : 0.0000 (0.00%)\n","Wage_Inflation      : 0.1552 (15.52%)\n","\n","Total               : 0.9059\n","\n","----------------------------------------------------------------------\n","CHAIR VS OTHER SPEAKERS COMPARISON\n","----------------------------------------------------------------------\n","\n","Labor Share:\n","  Chair average: 73.67%\n","  Other average: 70.69%\n","\n","Top 3 Labor Indicators (Chair):\n","  Unemployment        : 0.3604\n","  Wages               : 0.2002\n","  Employment          : 0.1357\n","\n","Top 3 Labor Indicators (Other):\n","  Unemployment        : 0.4364\n","  Wages               : 0.2362\n","  Hiring              : 0.0962\n","\n","======================================================================\n","PROCESSING COMPLETE!\n","======================================================================\n"]}]}]}