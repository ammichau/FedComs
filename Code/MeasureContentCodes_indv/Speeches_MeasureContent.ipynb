{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMW/MFlHn+7IIxrW8gNDHwb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import re\n","import json\n","import random\n","import time\n","from glob import glob\n","\n","# Set random seed for reproducibility\n","seed = int(time.time())\n","random.seed(seed)\n","np.random.seed(seed)\n","\n","# Directory paths\n","input_dir = '/content/drive/MyDrive/FedComs/Speeches/fed_speeches'\n","cleaned_output_dir = '/content/drive/MyDrive/FedComs/Speeches/fed_speeches_clean'\n","\n","# ============================================================================\n","# STEP 1: CLEAN SPEECHES\n","# ============================================================================\n","\n","def remove_video_controls_text(text):\n","    \"\"\"Remove the video player control instructions.\"\"\"\n","    video_controls_pattern = (\n","        r'\\[Space Bar\\] toggles play/pause;'\n","        r'\\[Right/Left Arrows\\] seeks the video forwards and back \\(5 sec \\);'\n","        r'\\[Up/Down Arrows\\] increase/decrease volume;'\n","        r'\\[F\\] toggles fullscreen on/off \\(Except IE 11\\);'\n","        r'The \\[Tab\\] key may be used in combination with the \\[Enter/Return\\] key '\n","        r'to navigate and activate control buttons, such as caption on/off\\.;'\n","    )\n","    text = re.sub(video_controls_pattern, '', text, flags=re.IGNORECASE)\n","\n","    # Also handle variations with different spacing/formatting\n","    text = re.sub(r'\\[Space Bar\\].*?caption on/off\\.;?\\s*', '', text, flags=re.IGNORECASE | re.DOTALL)\n","\n","    return text\n","\n","def remove_references_section(text):\n","    \"\"\"\n","    Remove bibliography/references section with careful handling.\n","    Only removes if 'References' appears to be a section header.\n","    \"\"\"\n","    lines = text.split('\\n')\n","    references_idx = -1\n","\n","    for i, line in enumerate(lines):\n","        line_stripped = line.strip()\n","\n","        # Check if line is just \"References\" or \"REFERENCES\" (case insensitive)\n","        if re.match(r'^references?$', line_stripped, re.IGNORECASE):\n","            # Verify next few lines look like bibliography entries\n","            next_lines = '\\n'.join(lines[i+1:min(i+4, len(lines))])\n","\n","            # Check for bibliography indicators in next few lines\n","            bibliography_indicators = [\n","                r'\\d{4}[a-z]?\\.?\\s',  # Year followed by period/space\n","                r'\\([12]\\d{3}[a-z]?\\)',  # Year in parentheses\n","                r'[A-Z][a-z]+,\\s+[A-Z]\\.',  # Last name, First initial\n","                r'Journal of',\n","                r'Review of',\n","                r'Federal Reserve',\n","                r'Working Paper',\n","                r'https?://',\n","                r'doi:',\n","            ]\n","\n","            if any(re.search(pattern, next_lines, re.IGNORECASE) for pattern in bibliography_indicators):\n","                references_idx = i\n","                break\n","\n","    # If we found a References section, remove it\n","    if references_idx >= 0:\n","        text = '\\n'.join(lines[:references_idx])\n","\n","    return text\n","\n","def fix_text_encoding(text):\n","    \"\"\"Fix common text encoding issues.\"\"\"\n","    text = text.replace('â€\"', '—')\n","    text = text.replace('â€\"', '—')\n","    text = text.replace('â€œ', '\"')\n","    text = text.replace('â€', '\"')\n","    text = text.replace('\\u2013', '–')\n","    text = text.replace('\\u2014', '—')\n","    text = text.replace('\\u2018', \"'\")\n","    text = text.replace('\\u2019', \"'\")\n","    text = text.replace('\\u201c', '\"')\n","    text = text.replace('\\u201d', '\"')\n","    text = text.replace('\\u2026', '...')\n","    text = re.sub(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f\\x7f-\\x9f]', '', text)\n","    return text\n","\n","def clean_speech_text(text):\n","    \"\"\"Clean speech text by fixing encoding and removing unwanted content.\"\"\"\n","    text = fix_text_encoding(text)\n","    text = remove_video_controls_text(text)\n","    text = remove_references_section(text)\n","\n","    # Clean up excessive whitespace\n","    text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n","    text = re.sub(r' +', ' ', text)\n","\n","    return text.strip()\n","\n","print(\"\\nCleaning speech files...\")\n","print(f\"Reading from: {input_dir}\")\n","\n","# Get all CSV files in the input directory\n","csv_files = glob(os.path.join(input_dir, '*.csv'))\n","print(f\"Found {len(csv_files)} speech files\")\n","\n","if len(csv_files) == 0:\n","    print(\"ERROR: No CSV files found in input directory!\")\n","    print(f\"Please check that files exist in: {input_dir}\")\n","else:\n","    # Process each file\n","    cleaned_count = 0\n","    for csv_file in csv_files:\n","        filename = os.path.basename(csv_file)\n","        print(f\"Processing {filename}...\")\n","\n","        try:\n","            # Read the speech file\n","            df = pd.read_csv(csv_file, encoding='utf-8', encoding_errors='replace')\n","\n","            # Find the text column\n","            text_col = None\n","            for col in df.columns:\n","                if 'text' in col.lower():\n","                    text_col = col\n","                    break\n","\n","            if text_col is None:\n","                print(f\"  Warning: No text column found in {filename}, skipping...\")\n","                continue\n","\n","            # Clean the text\n","            df[text_col] = df[text_col].apply(lambda x: clean_speech_text(str(x)) if pd.notna(x) else '')\n","\n","            # Save cleaned version\n","            output_file = os.path.join(cleaned_output_dir, filename)\n","            df.to_csv(output_file, index=False)\n","            cleaned_count += 1\n","\n","        except Exception as e:\n","            print(f\"  Error processing {filename}: {e}\")\n","            continue\n","\n","    print(f\"\\nCleaned {cleaned_count} speech files\")\n","    print(f\"Cleaned files saved to: {cleaned_output_dir}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGIqK9rehKV0","executionInfo":{"status":"ok","timestamp":1760022591996,"user_tz":300,"elapsed":6498,"user":{"displayName":"Amanda Michaud","userId":"14525267344116117436"}},"outputId":"80bdd392-03d7-40a4-922c-591c6b4aa080"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","Cleaning speech files...\n","Reading from: /content/drive/MyDrive/FedComs/Speeches/fed_speeches\n","Found 25 speech files\n","Processing susan_bies_speeches.csv...\n","Processing frederic_mishkin_speeches.csv...\n","Processing ben_bernanke_speeches.csv...\n","Processing donald_kohn_speeches.csv...\n","Processing mark_olson_speeches.csv...\n","Processing roger_jr_speeches.csv...\n","Processing kevin_warsh_speeches.csv...\n","Processing randall_kroszner_speeches.csv...\n","Processing sarah_raskin_speeches.csv...\n","Processing janet_yellen_speeches.csv...\n","Processing elizabeth_duke_speeches.csv...\n","Processing daniel_tarullo_speeches.csv...\n","Processing jeremy_stein_speeches.csv...\n","Processing jerome_powell_speeches.csv...\n","Processing stanley_fischer_speeches.csv...\n","Processing lael_brainard_speeches.csv...\n","Processing randal_quarles_speeches.csv...\n","Processing richard_clarida_speeches.csv...\n","Processing michelle_bowman_speeches.csv...\n","Processing christopher_waller_speeches.csv...\n","Processing michael_barr_speeches.csv...\n","Processing lisa_cook_speeches.csv...\n","Processing philip_jefferson_speeches.csv...\n","Processing adriana_kugler_speeches.csv...\n","Processing miran_speeches.csv...\n","\n","Cleaned 25 speech files\n","Cleaned files saved to: /content/drive/MyDrive/FedComs/Speeches/fed_speeches_clean\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import os\n","import pandas as pd\n","import numpy as np\n","import re\n","import json\n","import random\n","import time\n","from glob import glob\n","\n","# Set random seed for reproducibility\n","seed = int(time.time())\n","random.seed(seed)\n","np.random.seed(seed)\n","\n","# Directory paths\n","dict_dir = '/content/drive/MyDrive/FedComs/Dictionaries'\n","input_dir = '/content/drive/MyDrive/FedComs/Speeches/fed_speeches'\n","cleaned_output_dir = '/content/drive/MyDrive/FedComs/Speeches/fed_speeches_clean'\n","validation_output_dir = '/content/drive/MyDrive/FedComs/Validation_Sets'\n","summary_output_dir = '/content/drive/MyDrive/FedComs/Speeches'\n","\n","# Create output directories if they don't exist\n","for directory in [cleaned_output_dir, validation_output_dir, summary_output_dir]:\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","os.chdir(summary_output_dir)\n","print(f\"Current working directory: {os.getcwd()}\")\n","\n","# ============================================================================\n","# STEP 1: CLEAN SPEECHES\n","# ============================================================================\n","\n","def remove_video_controls_text(text):\n","    \"\"\"Remove the video player control instructions.\"\"\"\n","    video_controls_pattern = (\n","        r'\\[Space Bar\\] toggles play/pause;'\n","        r'\\[Right/Left Arrows\\] seeks the video forwards and back \\(5 sec \\);'\n","        r'\\[Up/Down Arrows\\] increase/decrease volume;'\n","        r'\\[F\\] toggles fullscreen on/off \\(Except IE 11\\);'\n","        r'The \\[Tab\\] key may be used in combination with the \\[Enter/Return\\] key '\n","        r'to navigate and activate control buttons, such as caption on/off\\.;'\n","    )\n","    text = re.sub(video_controls_pattern, '', text, flags=re.IGNORECASE)\n","\n","    # Also handle variations with different spacing/formatting\n","    text = re.sub(r'\\[Space Bar\\].*?caption on/off\\.;?\\s*', '', text, flags=re.IGNORECASE | re.DOTALL)\n","\n","    return text\n","\n","def remove_references_section(text):\n","    \"\"\"\n","    Remove bibliography/references section with careful handling.\n","    Only removes if 'References' appears to be a section header.\n","    \"\"\"\n","    lines = text.split('\\n')\n","    references_idx = -1\n","\n","    for i, line in enumerate(lines):\n","        line_stripped = line.strip()\n","\n","        # Check if line is just \"References\" or \"REFERENCES\" (case insensitive)\n","        if re.match(r'^references?$', line_stripped, re.IGNORECASE):\n","            # Verify next few lines look like bibliography entries\n","            next_lines = '\\n'.join(lines[i+1:min(i+4, len(lines))])\n","\n","            # Check for bibliography indicators in next few lines\n","            bibliography_indicators = [\n","                r'\\d{4}[a-z]?\\.?\\s',  # Year followed by period/space\n","                r'\\([12]\\d{3}[a-z]?\\)',  # Year in parentheses\n","                r'[A-Z][a-z]+,\\s+[A-Z]\\.',  # Last name, First initial\n","                r'Journal of',\n","                r'Review of',\n","                r'Federal Reserve',\n","                r'Working Paper',\n","                r'https?://',\n","                r'doi:',\n","            ]\n","\n","            if any(re.search(pattern, next_lines, re.IGNORECASE) for pattern in bibliography_indicators):\n","                references_idx = i\n","                break\n","\n","    # If we found a References section, remove it\n","    if references_idx >= 0:\n","        text = '\\n'.join(lines[:references_idx])\n","\n","    return text\n","\n","def fix_text_encoding(text):\n","    \"\"\"Fix common text encoding issues.\"\"\"\n","    text = text.replace('â€\"', '—')\n","    text = text.replace('â€\"', '—')\n","    text = text.replace('â€œ', '\"')\n","    text = text.replace('â€', '\"')\n","    text = text.replace('\\u2013', '–')\n","    text = text.replace('\\u2014', '—')\n","    text = text.replace('\\u2018', \"'\")\n","    text = text.replace('\\u2019', \"'\")\n","    text = text.replace('\\u201c', '\"')\n","    text = text.replace('\\u201d', '\"')\n","    text = text.replace('\\u2026', '...')\n","    text = re.sub(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f\\x7f-\\x9f]', '', text)\n","    return text\n","\n","def clean_speech_text(text):\n","    \"\"\"Clean speech text by fixing encoding and removing unwanted content.\"\"\"\n","    text = fix_text_encoding(text)\n","    text = remove_video_controls_text(text)\n","    text = remove_references_section(text)\n","\n","    # Clean up excessive whitespace\n","    text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)\n","    text = re.sub(r' +', ' ', text)\n","\n","    return text.strip()\n","\n","print(\"\\nCleaning speech files...\")\n","print(f\"Reading from: {input_dir}\")\n","\n","# Get all CSV files in the input directory\n","csv_files = glob(os.path.join(input_dir, '*.csv'))\n","print(f\"Found {len(csv_files)} speech files\")\n","\n","if len(csv_files) == 0:\n","    print(\"ERROR: No CSV files found in input directory!\")\n","    print(f\"Please check that files exist in: {input_dir}\")\n","else:\n","    # Process each file\n","    cleaned_count = 0\n","    for csv_file in csv_files:\n","        filename = os.path.basename(csv_file)\n","        print(f\"Processing {filename}...\")\n","\n","        try:\n","            # Read the speech file\n","            df = pd.read_csv(csv_file, encoding='utf-8', encoding_errors='replace')\n","\n","            # Find the text column\n","            text_col = None\n","            for col in df.columns:\n","                if 'text' in col.lower():\n","                    text_col = col\n","                    break\n","\n","            if text_col is None:\n","                print(f\"  Warning: No text column found in {filename}, skipping...\")\n","                continue\n","\n","            # Clean the text\n","            df[text_col] = df[text_col].apply(lambda x: clean_speech_text(str(x)) if pd.notna(x) else '')\n","\n","            # Save cleaned version\n","            output_file = os.path.join(cleaned_output_dir, filename)\n","            df.to_csv(output_file, index=False)\n","            cleaned_count += 1\n","\n","        except Exception as e:\n","            print(f\"  Error processing {filename}: {e}\")\n","            continue\n","\n","    print(f\"\\nCleaned {cleaned_count} speech files\")\n","    print(f\"Cleaned files saved to: {cleaned_output_dir}\")\n","\n","# ============================================================================\n","# STEP 2: LOAD DICTIONARIES\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"LOADING DICTIONARIES\")\n","print(\"=\"*70)\n","\n","with open(os.path.join(dict_dir, 'labor_indicators.json'), 'r') as f:\n","    LABOR_INDICATORS = json.load(f)\n","\n","with open(os.path.join(dict_dir, 'inflation_indicators.json'), 'r') as f:\n","    INFLATION_INDICATORS = json.load(f)\n","\n","with open(os.path.join(dict_dir, 'inflation_pattern_mapping.json'), 'r') as f:\n","    INFLATION_PATTERN_TO_INDICATOR = json.load(f)\n","\n","print(\"Dictionaries loaded successfully!\")\n","print(f\"Labor indicators: {list(LABOR_INDICATORS.keys())}\")\n","print(f\"Inflation categories: {list(INFLATION_INDICATORS.keys())}\")\n","\n","# ============================================================================\n","# STEP 3: SENTENCE SPLITTING AND CLASSIFICATION FUNCTIONS\n","# ============================================================================\n","\n","def split_into_sentences(text):\n","    \"\"\"Split text into sentences, preserving initials and abbreviations.\"\"\"\n","    text = fix_text_encoding(text)\n","\n","    abbreviations = [\n","        r'\\bU\\.S\\.A\\.', r'\\bU\\.S\\.', r'\\bU\\.K\\.', r'\\bE\\.U\\.',\n","        r'\\bSt\\.', r'\\bMr\\.', r'\\bMrs\\.', r'\\bMs\\.', r'\\bDr\\.',\n","        r'\\bProf\\.', r'\\bSr\\.', r'\\bJr\\.', r'\\bvs\\.', r'\\betc\\.',\n","        r'\\bi\\.e\\.', r'\\be\\.g\\.', r'\\bVol\\.', r'\\bNo\\.', r'\\bpp\\.',\n","        r'\\bCo\\.', r'\\bInc\\.', r'\\bLtd\\.', r'\\bCorp\\.',\n","        r'\\bPh\\.D\\.', r'\\bM\\.A\\.', r'\\bM\\.S\\.', r'\\bB\\.A\\.',\n","        r'\\bD\\.C\\.', r'\\bA\\.M\\.', r'\\bP\\.M\\.'\n","    ]\n","\n","    for idx, abbr in enumerate(abbreviations):\n","        text = re.sub(abbr, f'<ABBR_{idx}>', text, flags=re.IGNORECASE)\n","\n","    text = re.sub(r'\\b([A-Z])\\.(\\s+[A-Z]\\.)*(?=\\s+[A-Z][a-z]+)', lambda m: m.group(0).replace('.', f'<NAME>'), text)\n","    text = re.sub(r'\\b\\d+\\.\\d+\\b', lambda m: m.group(0).replace('.', '<DEC>'), text)\n","\n","    voting_pattern = r'((?:Voting for|Voting against)\\s+[^.!?]+?)([.!?]+\\s+|$)'\n","    voting_matches = []\n","    def store_voting_match(match):\n","        voting_matches.append(match.group(1))\n","        return f'<VOTE_{len(voting_matches) - 1}>'\n","    text = re.sub(voting_pattern, store_voting_match, text)\n","\n","    sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z]|$)', text)\n","    sentences = [s.strip() for s in sentences if s.strip()]\n","\n","    restored_sentences = []\n","    for sentence in sentences:\n","        for idx in range(len(abbreviations)):\n","            sentence = sentence.replace(f'<ABBR_{idx}>', abbreviations[idx].replace(r'\\b', '').replace(r'\\.', '.'))\n","        sentence = sentence.replace('<NAME>', '.')\n","        sentence = sentence.replace('<DEC>', '.')\n","        for i, voting_list in enumerate(voting_matches):\n","            placeholder = f'<VOTE_{i}>'\n","            if placeholder in sentence:\n","                sentence = sentence.replace(placeholder, voting_list)\n","        restored_sentences.append(sentence)\n","\n","    return restored_sentences\n","\n","def check_keywords_in_sentence(sentence, keywords):\n","    \"\"\"Check if any keyword appears in the sentence.\"\"\"\n","    sentence_lower = sentence.lower()\n","    for keyword in keywords:\n","        pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n","        if re.search(pattern, sentence_lower):\n","            return True\n","    return False\n","\n","def check_employment_indicator(sentence, keywords):\n","    \"\"\"Check for Employment indicator, excluding maximum/full employment.\"\"\"\n","    sentence_lower = sentence.lower()\n","\n","    if re.search(r'\\b(?:maximum|full)\\s+employment\\b', sentence_lower):\n","        return False\n","    if re.search(r'\\bemployment\\s+goal\\b', sentence_lower):\n","        return False\n","\n","    for keyword in keywords:\n","        pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n","        if re.search(pattern, sentence_lower):\n","            return True\n","    return False\n","\n","def check_general_labor_term(sentence):\n","    \"\"\"Check if sentence contains general labor terms.\"\"\"\n","    sentence_lower = sentence.lower()\n","    general_labor_keywords = LABOR_INDICATORS.get(\"General Labor\", [])\n","    for keyword in general_labor_keywords:\n","        pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n","        if re.search(pattern, sentence_lower):\n","            return True\n","    return False\n","\n","def check_general_inflation_terms(sentence):\n","    \"\"\"Check if sentence contains general inflation terms.\"\"\"\n","    sentence_lower = sentence.lower()\n","    general_inflation_patterns = INFLATION_INDICATORS.get(\"General Inflation\", {}).get(\"general_patterns\", [])\n","    for pattern in general_inflation_patterns:\n","        if re.search(pattern, sentence_lower, re.IGNORECASE):\n","            return True\n","    return False\n","\n","def check_inflation_sentence(sentence):\n","    \"\"\"Check if sentence mentions any inflation indicator.\"\"\"\n","    mentioned_indicators = set()\n","    sentence_lower = sentence.lower()\n","\n","    for category, subcategories in INFLATION_INDICATORS.items():\n","        for pattern_name, pattern_list in subcategories.items():\n","            for pattern in pattern_list:\n","                if re.search(pattern, sentence_lower, re.IGNORECASE):\n","                    indicator_name = INFLATION_PATTERN_TO_INDICATOR.get(pattern_name, \"Other\")\n","                    mentioned_indicators.add(indicator_name)\n","                    break\n","\n","    if \"Core_CPI\" in mentioned_indicators and \"Core\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Core\")\n","\n","    if \"Core_PCE\" in mentioned_indicators and \"Core\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Core\")\n","\n","    if \"Headline_CPI\" in mentioned_indicators and \"Headline\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Headline\")\n","\n","    if \"Headline_PCE\" in mentioned_indicators and \"Headline\" in mentioned_indicators:\n","        mentioned_indicators.discard(\"Headline\")\n","\n","    return mentioned_indicators\n","\n","def classify_sentence(sentence):\n","    \"\"\"Classify a single sentence and return its indicators.\"\"\"\n","    labor_specific_found = False\n","    labor_indicators_in_sentence = set()\n","\n","    for indicator, keywords in LABOR_INDICATORS.items():\n","        if indicator == \"General Labor\":\n","            continue\n","\n","        if indicator == \"Employment\":\n","            if check_employment_indicator(sentence, keywords):\n","                labor_indicators_in_sentence.add(indicator)\n","                labor_specific_found = True\n","        else:\n","            if check_keywords_in_sentence(sentence, keywords):\n","                labor_indicators_in_sentence.add(indicator)\n","                labor_specific_found = True\n","\n","    labor_general_found = check_general_labor_term(sentence)\n","    labor_found = labor_specific_found or labor_general_found\n","\n","    inflation_indicators_in_sentence = check_inflation_sentence(sentence)\n","    inflation_specific_found = bool(inflation_indicators_in_sentence)\n","\n","    inflation_general_found = check_general_inflation_terms(sentence)\n","    inflation_found = inflation_specific_found or inflation_general_found\n","\n","    if labor_found and inflation_found:\n","        classification = \"Both\"\n","    elif labor_found:\n","        classification = \"Labor\"\n","    elif inflation_found:\n","        classification = \"Inflation\"\n","    else:\n","        classification = \"Neither\"\n","\n","    return {\n","        'classification': classification,\n","        'labor_indicators': list(labor_indicators_in_sentence),\n","        'inflation_indicators': list(inflation_indicators_in_sentence)\n","    }\n","\n","def analyze_speech(text):\n","    \"\"\"Analyze a single speech for labor and inflation content.\"\"\"\n","    sentences = split_into_sentences(text)\n","    total_sentences = len(sentences)\n","\n","    labor_sentences = 0\n","    inflation_sentences = 0\n","    both_sentences = 0\n","\n","    labor_indicator_counts = {indicator: 0 for indicator in LABOR_INDICATORS.keys() if indicator != \"General Labor\"}\n","    inflation_indicator_list = sorted(list(set(\n","        indicator for indicator in INFLATION_PATTERN_TO_INDICATOR.values()\n","        if indicator not in [\"General_Inflation\", \"Other\"]\n","    )))\n","    inflation_indicator_counts = {indicator: 0 for indicator in inflation_indicator_list}\n","\n","    sentence_data_list = []\n","\n","    for sent_idx, sentence in enumerate(sentences):\n","        classification_result = classify_sentence(sentence)\n","\n","        labor_indicators_filtered = [ind for ind in classification_result['labor_indicators']\n","                                      if ind != \"General Labor\"]\n","        inflation_indicators_filtered = [ind for ind in classification_result['inflation_indicators']\n","                                          if ind not in [\"General_Inflation\", \"Other\"]]\n","\n","        sentence_data = {\n","            'sentence_number': sent_idx + 1,\n","            'sentence_text': sentence,\n","            'classification': classification_result['classification'],\n","            'labor_indicators': ', '.join(sorted(labor_indicators_filtered)) if labor_indicators_filtered else '',\n","            'inflation_indicators': ', '.join(sorted(inflation_indicators_filtered)) if inflation_indicators_filtered else ''\n","        }\n","        sentence_data_list.append(sentence_data)\n","\n","        labor_specific_found = bool(classification_result['labor_indicators'])\n","        labor_general_found = check_general_labor_term(sentence)\n","        labor_found = labor_specific_found or labor_general_found\n","\n","        inflation_specific_found = bool(classification_result['inflation_indicators'])\n","        inflation_general_found = check_general_inflation_terms(sentence)\n","        inflation_found = inflation_specific_found or inflation_general_found\n","\n","        if labor_found and inflation_found:\n","            both_sentences += 1\n","            labor_sentences += 1\n","            inflation_sentences += 1\n","        elif labor_found:\n","            labor_sentences += 1\n","        elif inflation_found:\n","            inflation_sentences += 1\n","\n","        for indicator in classification_result['labor_indicators']:\n","            if indicator in labor_indicator_counts:\n","                labor_indicator_counts[indicator] += 1\n","\n","        for indicator in classification_result['inflation_indicators']:\n","            if indicator in inflation_indicator_counts:\n","                inflation_indicator_counts[indicator] += 1\n","\n","    total_labor_mentions = sum(labor_indicator_counts.values())\n","    total_inflation_mentions = sum(inflation_indicator_counts.values())\n","\n","    labor_emphasis = {}\n","    for indicator, count in labor_indicator_counts.items():\n","        labor_emphasis[f\"labor_emphasis_{indicator}\"] = count / total_labor_mentions if total_labor_mentions > 0 else 0\n","\n","    inflation_emphasis = {}\n","    for indicator, count in inflation_indicator_counts.items():\n","        inflation_emphasis[f\"inflation_emphasis_{indicator}\"] = count / total_inflation_mentions if total_inflation_mentions > 0 else 0\n","\n","    labor_sentence_share = {}\n","    for indicator, count in labor_indicator_counts.items():\n","        labor_sentence_share[f\"labor_share_total_sentences_{indicator}\"] = count / total_sentences if total_sentences > 0 else 0\n","\n","    inflation_sentence_share = {}\n","    for indicator, count in inflation_indicator_counts.items():\n","        inflation_sentence_share[f\"inflation_share_total_sentences_{indicator}\"] = count / total_sentences if total_sentences > 0 else 0\n","\n","    labor_inflation_total = labor_sentences + inflation_sentences - both_sentences\n","    labor_share_of_labor_inflation = labor_sentences / labor_inflation_total if labor_inflation_total > 0 else 0\n","\n","    summary_results = {\n","        'sentences_on_labor': labor_sentences,\n","        'sentences_on_inflation': inflation_sentences,\n","        'sentences_on_both': both_sentences,\n","        'total_sentences': total_sentences,\n","        'labor_share_of_labor_inflation_sentences': labor_share_of_labor_inflation\n","    }\n","\n","    for indicator, count in labor_indicator_counts.items():\n","        summary_results[f'labor_{indicator}_count'] = count\n","\n","    for indicator, count in inflation_indicator_counts.items():\n","        summary_results[f'inflation_{indicator}_count'] = count\n","\n","    summary_results.update(labor_emphasis)\n","    summary_results.update(inflation_emphasis)\n","    summary_results.update(labor_sentence_share)\n","    summary_results.update(inflation_sentence_share)\n","\n","    return summary_results, sentence_data_list\n","\n","# ============================================================================\n","# STEP 4: CLASSIFY SPEECH CONTENT\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"CLASSIFYING SPEECH CONTENT\")\n","print(\"=\"*70)\n","\n","cleaned_files = glob(os.path.join(cleaned_output_dir, '*.csv'))\n","print(f\"Found {len(cleaned_files)} cleaned speech files to classify\")\n","\n","results_list = []\n","all_sentences = []\n","\n","for idx, csv_file in enumerate(cleaned_files):\n","    filename = os.path.basename(csv_file)\n","\n","    if idx % 5 == 0 or len(cleaned_files) <= 10:\n","        print(f\"Processing file {idx+1}/{len(cleaned_files)}: {filename}\")\n","\n","    try:\n","        df = pd.read_csv(csv_file, encoding='utf-8', encoding_errors='replace')\n","\n","        text_col = None\n","        for col in df.columns:\n","            if 'text' in col.lower():\n","                text_col = col\n","                break\n","\n","        if text_col is None:\n","            print(f\"  Warning: No text column in {filename}, skipping...\")\n","            continue\n","\n","        for row_idx, row in df.iterrows():\n","            if pd.isna(row[text_col]):\n","                text = ''\n","            else:\n","                text = str(row[text_col])\n","\n","            if len(text.strip()) == 0:\n","                continue\n","\n","            summary_results, sentence_data_list = analyze_speech(text)\n","\n","            for col in df.columns:\n","                col_lower = col.lower()\n","                if col_lower not in ['text', 'speech_text']:\n","                    summary_results[col] = str(row[col]) if pd.notna(row[col]) else ''\n","\n","            results_list.append(summary_results)\n","\n","            for sentence_data in sentence_data_list:\n","                official_name = ''\n","                for name_col in ['official_name', 'name', 'Name', 'speaker', 'Speaker']:\n","                    if name_col in row and pd.notna(row[name_col]):\n","                        official_name = str(row[name_col])\n","                        break\n","\n","                sentence_data['official_name'] = official_name\n","\n","                date_val = ''\n","                for date_col in ['date', 'Date']:\n","                    if date_col in row and pd.notna(row[date_col]):\n","                        date_val = str(row[date_col])\n","                        break\n","                sentence_data['date'] = date_val\n","\n","                all_sentences.append(sentence_data)\n","\n","    except Exception as e:\n","        print(f\"  Error processing {filename}: {e}\")\n","        import traceback\n","        print(f\"  Full traceback: {traceback.format_exc()}\")\n","        continue\n","\n","# Create summary dataframe\n","results_df = pd.DataFrame(results_list)\n","\n","if len(results_df) > 0:\n","    priority_cols = ['date', 'Date', 'official_name', 'name', 'Name', 'title', 'Title']\n","    first_cols = [col for col in priority_cols if col in results_df.columns]\n","    other_cols = [col for col in results_df.columns if col not in first_cols]\n","    results_df = results_df[first_cols + other_cols]\n","\n","    date_col = None\n","    for col in ['date', 'Date']:\n","        if col in results_df.columns:\n","            date_col = col\n","            break\n","\n","    if date_col:\n","        try:\n","            results_df = results_df.sort_values(date_col)\n","        except:\n","            pass\n","\n","    summary_output_file = os.path.join(summary_output_dir, 'speeches_content.csv')\n","    results_df.to_csv(summary_output_file, index=False)\n","    print(f\"\\nSummary dataset saved to: {summary_output_file}\")\n","    print(f\"Shape: {results_df.shape}\")\n","\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"SUMMARY STATISTICS\")\n","    print(\"=\"*70)\n","    print(f\"\\nNumber of speeches analyzed: {len(results_df)}\")\n","    print(f\"\\nAverage sentences per speech: {results_df['total_sentences'].mean():.1f}\")\n","    print(f\"Average labor sentences: {results_df['sentences_on_labor'].mean():.1f}\")\n","    print(f\"Average inflation sentences: {results_df['sentences_on_inflation'].mean():.1f}\")\n","    print(f\"Average sentences on both: {results_df['sentences_on_both'].mean():.1f}\")\n","    print(f\"Average labor share of labor/inflation: {results_df['labor_share_of_labor_inflation_sentences'].mean():.2%}\")\n","\n","    labor_emphasis_cols = [col for col in results_df.columns if col.startswith('labor_emphasis_')]\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"AVERAGE LABOR EMPHASIS VECTORS\")\n","    print(\"-\"*70)\n","    for col in sorted(labor_emphasis_cols):\n","        indicator_name = col.replace('labor_emphasis_', '')\n","        avg_emphasis = results_df[col].mean()\n","        print(f\"{indicator_name:20s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","    total_labor_emphasis = results_df[labor_emphasis_cols].mean().sum()\n","    print(f\"\\n{'Total':20s}: {total_labor_emphasis:.4f}\")\n","\n","    inflation_emphasis_cols = [col for col in results_df.columns if col.startswith('inflation_emphasis_')]\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"AVERAGE INFLATION EMPHASIS VECTORS\")\n","    print(\"-\"*70)\n","    for col in sorted(inflation_emphasis_cols):\n","        indicator_name = col.replace('inflation_emphasis_', '')\n","        avg_emphasis = results_df[col].mean()\n","        print(f\"{indicator_name:20s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","    total_inflation_emphasis = results_df[inflation_emphasis_cols].mean().sum()\n","    print(f\"\\n{'Total':20s}: {total_inflation_emphasis:.4f}\")\n","\n","    print(\"\\n\" + \"-\"*70)\n","    print(\"OFFICIALS BY LABOR SHARE OF LABOR/INFLATION\")\n","    print(\"-\"*70)\n","\n","    official_col = None\n","    for col in ['official_name', 'name', 'Name', 'speaker', 'Speaker']:\n","        if col in results_df.columns:\n","            official_col = col\n","            break\n","\n","    if official_col:\n","        official_labor_share = results_df.groupby(official_col)['labor_share_of_labor_inflation_sentences'].agg(['mean', 'count'])\n","        official_labor_share = official_labor_share[official_labor_share['count'] >= 2]\n","        official_labor_share = official_labor_share.sort_values('mean', ascending=False)\n","\n","        if len(official_labor_share) >= 4:\n","            print(\"\\nTop 4 Officials (Highest Labor Share):\")\n","            top_4 = official_labor_share.head(4)\n","            for idx, (official, row) in enumerate(top_4.iterrows(), 1):\n","                print(f\"{idx}. {official:30s}: {row['mean']:.2%} (n={int(row['count'])})\")\n","\n","            print(\"\\nBottom 4 Officials (Lowest Labor Share):\")\n","            bottom_4 = official_labor_share.tail(4)\n","            for idx, (official, row) in enumerate(bottom_4.iterrows(), 1):\n","                print(f\"{idx}. {official:30s}: {row['mean']:.2%} (n={int(row['count'])})\")\n","\n","            print(\"\\n\" + \"=\"*70)\n","            print(\"EMPHASIS VECTORS FOR TOP 4 OFFICIALS\")\n","            print(\"=\"*70)\n","\n","            for official_name in top_4.index:\n","                official_speeches = results_df[results_df[official_col] == official_name]\n","\n","                print(f\"\\n{official_name} (Labor Share: {top_4.loc[official_name, 'mean']:.2%})\")\n","                print(\"-\" * 70)\n","\n","                print(\"Labor Emphasis:\")\n","                for col in sorted(labor_emphasis_cols):\n","                    indicator_name = col.replace('labor_emphasis_', '')\n","                    avg_emphasis = official_speeches[col].mean()\n","                    if avg_emphasis > 0:\n","                        print(f\"  {indicator_name:25s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","                print(\"\\nInflation Emphasis:\")\n","                for col in sorted(inflation_emphasis_cols):\n","                    indicator_name = col.replace('inflation_emphasis_', '')\n","                    avg_emphasis = official_speeches[col].mean()\n","                    if avg_emphasis > 0:\n","                        print(f\"  {indicator_name:25s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","            print(\"\\n\" + \"=\"*70)\n","            print(\"EMPHASIS VECTORS FOR BOTTOM 4 OFFICIALS\")\n","            print(\"=\"*70)\n","\n","            for official_name in bottom_4.index:\n","                official_speeches = results_df[results_df[official_col] == official_name]\n","\n","                print(f\"\\n{official_name} (Labor Share: {bottom_4.loc[official_name, 'mean']:.2%})\")\n","                print(\"-\" * 70)\n","\n","                print(\"Labor Emphasis:\")\n","                for col in sorted(labor_emphasis_cols):\n","                    indicator_name = col.replace('labor_emphasis_', '')\n","                    avg_emphasis = official_speeches[col].mean()\n","                    if avg_emphasis > 0:\n","                        print(f\"  {indicator_name:25s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","\n","                print(\"\\nInflation Emphasis:\")\n","                for col in sorted(inflation_emphasis_cols):\n","                    indicator_name = col.replace('inflation_emphasis_', '')\n","                    avg_emphasis = official_speeches[col].mean()\n","                    if avg_emphasis > 0:\n","                        print(f\"  {indicator_name:25s}: {avg_emphasis:.4f} ({avg_emphasis*100:.2f}%)\")\n","        else:\n","            print(f\"\\nNot enough officials with multiple speeches (found {len(official_labor_share)})\")\n","    else:\n","        print(\"\\nCould not find official name column\")\n","\n","else:\n","    print(\"\\nWarning: No results to save!\")\n","\n","# Create sentence-level dataframe and validation set\n","sentences_df = pd.DataFrame(all_sentences)\n","\n","if len(sentences_df) > 0:\n","    print(f\"\\nTotal sentences extracted: {len(sentences_df)}\")\n","    print(\"\\nClassification distribution:\")\n","    print(sentences_df['classification'].value_counts())\n","\n","    n_labor = 15\n","    n_inflation = 15\n","    n_both = 5\n","    n_neither = 10\n","\n","    print(f\"\\nSampling sentences for validation...\")\n","    validation_samples = []\n","\n","    labor_sentences = sentences_df[sentences_df['classification'] == 'Labor']\n","    if len(labor_sentences) >= n_labor:\n","        validation_samples.append(labor_sentences.sample(n=n_labor, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(labor_sentences)} labor sentences available\")\n","        if len(labor_sentences) > 0:\n","            validation_samples.append(labor_sentences)\n","\n","    inflation_sentences = sentences_df[sentences_df['classification'] == 'Inflation']\n","    if len(inflation_sentences) >= n_inflation:\n","        validation_samples.append(inflation_sentences.sample(n=n_inflation, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(inflation_sentences)} inflation sentences available\")\n","        if len(inflation_sentences) > 0:\n","            validation_samples.append(inflation_sentences)\n","\n","    both_sentences = sentences_df[sentences_df['classification'] == 'Both']\n","    if len(both_sentences) >= n_both:\n","        validation_samples.append(both_sentences.sample(n=n_both, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(both_sentences)} both sentences available\")\n","        if len(both_sentences) > 0:\n","            validation_samples.append(both_sentences)\n","\n","    neither_sentences = sentences_df[sentences_df['classification'] == 'Neither']\n","    if len(neither_sentences) >= n_neither:\n","        validation_samples.append(neither_sentences.sample(n=n_neither, random_state=seed))\n","    else:\n","        print(f\"Warning: Only {len(neither_sentences)} neither sentences available\")\n","        if len(neither_sentences) > 0:\n","            validation_samples.append(neither_sentences)\n","\n","    if validation_samples:\n","        validation_df = pd.concat(validation_samples, ignore_index=True)\n","        validation_df = validation_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n","\n","        validation_output_file = os.path.join(validation_output_dir, 'speeches_validate.csv')\n","        validation_df.to_csv(validation_output_file, index=False)\n","\n","        print(f\"\\nValidation set created: {validation_output_file}\")\n","        print(f\"Total sentences in validation set: {len(validation_df)}\")\n","        print(f\"\\nValidation set distribution:\")\n","        print(validation_df['classification'].value_counts())\n","\n","        print(\"\\n\" + \"=\"*70)\n","        print(\"SAMPLE VALIDATION SENTENCES (10 examples)\")\n","        print(\"=\"*70)\n","\n","        sample_display = validation_df.head(10)\n","        for idx, row in sample_display.iterrows():\n","            print(f\"\\n[{idx+1}] Classification: {row['classification']}\")\n","            if row['official_name']:\n","                print(f\"    Official: {row['official_name']}\")\n","            if row['labor_indicators']:\n","                print(f\"    Labor Indicators: {row['labor_indicators']}\")\n","            if row['inflation_indicators']:\n","                print(f\"    Inflation Indicators: {row['inflation_indicators']}\")\n","            print(f\"    Sentence: {row['sentence_text'][:200]}{'...' if len(row['sentence_text']) > 200 else ''}\")\n","    else:\n","        print(\"\\nNo validation samples available\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"PROCESSING COMPLETE!\")\n","print(\"=\"*70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mvrygdA-e6FW","executionInfo":{"status":"ok","timestamp":1760022216883,"user_tz":300,"elapsed":188842,"user":{"displayName":"Amanda Michaud","userId":"14525267344116117436"}},"outputId":"30e5654b-9c0c-4317-a031-1dbff757aa42"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Current working directory: /content/drive/MyDrive/FedComs/Speeches\n","\n","Cleaning speech files...\n","Reading from: /content/drive/MyDrive/FedComs/Speeches/fed_speeches\n","Found 25 speech files\n","Processing susan_bies_speeches.csv...\n","Processing frederic_mishkin_speeches.csv...\n","Processing ben_bernanke_speeches.csv...\n","Processing donald_kohn_speeches.csv...\n","Processing mark_olson_speeches.csv...\n","Processing roger_jr_speeches.csv...\n","Processing kevin_warsh_speeches.csv...\n","Processing randall_kroszner_speeches.csv...\n","Processing sarah_raskin_speeches.csv...\n","Processing janet_yellen_speeches.csv...\n","Processing elizabeth_duke_speeches.csv...\n","Processing daniel_tarullo_speeches.csv...\n","Processing jeremy_stein_speeches.csv...\n","Processing jerome_powell_speeches.csv...\n","Processing stanley_fischer_speeches.csv...\n","Processing lael_brainard_speeches.csv...\n","Processing randal_quarles_speeches.csv...\n","Processing richard_clarida_speeches.csv...\n","Processing michelle_bowman_speeches.csv...\n","Processing christopher_waller_speeches.csv...\n","Processing michael_barr_speeches.csv...\n","Processing lisa_cook_speeches.csv...\n","Processing philip_jefferson_speeches.csv...\n","Processing adriana_kugler_speeches.csv...\n","Processing miran_speeches.csv...\n","\n","Cleaned 25 speech files\n","Cleaned files saved to: /content/drive/MyDrive/FedComs/Speeches/fed_speeches_clean\n","\n","======================================================================\n","LOADING DICTIONARIES\n","======================================================================\n","Dictionaries loaded successfully!\n","Labor indicators: ['General Labor', 'Employment', 'Unemployment', 'Participation', 'Wages', 'Vacancies', 'Quits', 'Layoffs', 'Hiring']\n","Inflation categories: ['General Inflation', 'Core Measures', 'Headline Measures', 'Sectoral Measures', 'Producer Price Index', 'Wage Inflation', 'Inflation Expectations', 'Commodity Prices']\n","\n","======================================================================\n","CLASSIFYING SPEECH CONTENT\n","======================================================================\n","Found 25 cleaned speech files to classify\n","Processing file 1/25: susan_bies_speeches.csv\n","Processing file 6/25: roger_jr_speeches.csv\n","Processing file 11/25: elizabeth_duke_speeches.csv\n","Processing file 16/25: lael_brainard_speeches.csv\n","Processing file 21/25: michael_barr_speeches.csv\n","\n","Summary dataset saved to: /content/drive/MyDrive/FedComs/Speeches/speeches_content.csv\n","Shape: (1121, 81)\n","\n","======================================================================\n","SUMMARY STATISTICS\n","======================================================================\n","\n","Number of speeches analyzed: 1121\n","\n","Average sentences per speech: 94.1\n","Average labor sentences: 9.0\n","Average inflation sentences: 6.7\n","Average sentences on both: 1.5\n","Average labor share of labor/inflation: 58.24%\n","\n","----------------------------------------------------------------------\n","AVERAGE LABOR EMPHASIS VECTORS\n","----------------------------------------------------------------------\n","Employment          : 0.1555 (15.55%)\n","Hiring              : 0.0770 (7.70%)\n","Layoffs             : 0.0179 (1.79%)\n","Participation       : 0.1427 (14.27%)\n","Quits               : 0.0045 (0.45%)\n","Unemployment        : 0.1666 (16.66%)\n","Vacancies           : 0.0264 (2.64%)\n","Wages               : 0.2007 (20.07%)\n","\n","Total               : 0.7913\n","\n","----------------------------------------------------------------------\n","AVERAGE INFLATION EMPHASIS VECTORS\n","----------------------------------------------------------------------\n","Commodity_Prices    : 0.0587 (5.87%)\n","Core                : 0.0268 (2.68%)\n","Core_CPI            : 0.0062 (0.62%)\n","Core_PCE            : 0.0200 (2.00%)\n","Energy              : 0.0264 (2.64%)\n","Food                : 0.0058 (0.58%)\n","Goods               : 0.0113 (1.13%)\n","Headline            : 0.0136 (1.36%)\n","Headline_CPI        : 0.0165 (1.65%)\n","Headline_PCE        : 0.0523 (5.23%)\n","Housing             : 0.0290 (2.90%)\n","Inflation_Expectations: 0.1322 (13.22%)\n","PPI                 : 0.0029 (0.29%)\n","Services            : 0.0000 (0.00%)\n","Wage_Inflation      : 0.0506 (5.06%)\n","\n","Total               : 0.4523\n","\n","----------------------------------------------------------------------\n","OFFICIALS BY LABOR SHARE OF LABOR/INFLATION\n","----------------------------------------------------------------------\n","\n","Top 4 Officials (Highest Labor Share):\n","1. Sarah Bloom Raskin            : 78.78% (n=16)\n","2. Janet L. Yellen               : 70.10% (n=64)\n","3. Elizabeth A. Duke             : 67.24% (n=20)\n","4. Richard H. Clarida            : 66.29% (n=42)\n","\n","Bottom 4 Officials (Lowest Labor Share):\n","1. Frederic S. Mishkin           : 41.20% (n=27)\n","2. Kevin M. Warsh                : 36.29% (n=11)\n","3. Donald L. Kohn                : 33.61% (n=34)\n","4. Roger W. Ferguson Jr.         : 25.05% (n=6)\n","\n","======================================================================\n","EMPHASIS VECTORS FOR TOP 4 OFFICIALS\n","======================================================================\n","\n","Sarah Bloom Raskin (Labor Share: 78.78%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.1114 (11.14%)\n","  Hiring                   : 0.0974 (9.74%)\n","  Layoffs                  : 0.0222 (2.22%)\n","  Participation            : 0.1389 (13.89%)\n","  Quits                    : 0.0012 (0.12%)\n","  Unemployment             : 0.3075 (30.75%)\n","  Vacancies                : 0.0025 (0.25%)\n","  Wages                    : 0.3189 (31.89%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.0179 (1.79%)\n","  Core                     : 0.0089 (0.89%)\n","  Energy                   : 0.0312 (3.12%)\n","  Food                     : 0.0045 (0.45%)\n","  Headline                 : 0.0179 (1.79%)\n","  Headline_PCE             : 0.0357 (3.57%)\n","  Housing                  : 0.1250 (12.50%)\n","  Inflation_Expectations   : 0.0625 (6.25%)\n","  Wage_Inflation           : 0.2589 (25.89%)\n","\n","Janet L. Yellen (Labor Share: 70.10%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.1877 (18.77%)\n","  Hiring                   : 0.0810 (8.10%)\n","  Layoffs                  : 0.0145 (1.45%)\n","  Participation            : 0.1196 (11.96%)\n","  Quits                    : 0.0058 (0.58%)\n","  Unemployment             : 0.2783 (27.83%)\n","  Vacancies                : 0.0150 (1.50%)\n","  Wages                    : 0.1888 (18.88%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.0821 (8.21%)\n","  Core                     : 0.0220 (2.20%)\n","  Core_CPI                 : 0.0030 (0.30%)\n","  Core_PCE                 : 0.0159 (1.59%)\n","  Energy                   : 0.0227 (2.27%)\n","  Food                     : 0.0068 (0.68%)\n","  Goods                    : 0.0161 (1.61%)\n","  Headline                 : 0.0130 (1.30%)\n","  Headline_CPI             : 0.0198 (1.98%)\n","  Headline_PCE             : 0.0629 (6.29%)\n","  Housing                  : 0.0059 (0.59%)\n","  Inflation_Expectations   : 0.1341 (13.41%)\n","  Wage_Inflation           : 0.1113 (11.13%)\n","\n","Elizabeth A. Duke (Labor Share: 67.24%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.1205 (12.05%)\n","  Hiring                   : 0.0808 (8.08%)\n","  Layoffs                  : 0.0206 (2.06%)\n","  Participation            : 0.2325 (23.25%)\n","  Unemployment             : 0.2633 (26.33%)\n","  Vacancies                : 0.1035 (10.35%)\n","  Wages                    : 0.1289 (12.89%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.0738 (7.38%)\n","  Core_PCE                 : 0.0071 (0.71%)\n","  Energy                   : 0.0560 (5.60%)\n","  Headline_PCE             : 0.0310 (3.10%)\n","  Housing                  : 0.1250 (12.50%)\n","  Inflation_Expectations   : 0.0571 (5.71%)\n","\n","Richard H. Clarida (Labor Share: 66.29%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.3498 (34.98%)\n","  Hiring                   : 0.0347 (3.47%)\n","  Layoffs                  : 0.0073 (0.73%)\n","  Participation            : 0.0968 (9.68%)\n","  Unemployment             : 0.4069 (40.69%)\n","  Vacancies                : 0.0015 (0.15%)\n","  Wages                    : 0.1030 (10.30%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.0388 (3.88%)\n","  Core                     : 0.0300 (3.00%)\n","  Core_CPI                 : 0.0145 (1.45%)\n","  Core_PCE                 : 0.0438 (4.38%)\n","  Energy                   : 0.0249 (2.49%)\n","  Headline                 : 0.0016 (0.16%)\n","  Headline_CPI             : 0.0162 (1.62%)\n","  Headline_PCE             : 0.1752 (17.52%)\n","  Inflation_Expectations   : 0.5468 (54.68%)\n","  Wage_Inflation           : 0.0368 (3.68%)\n","\n","======================================================================\n","EMPHASIS VECTORS FOR BOTTOM 4 OFFICIALS\n","======================================================================\n","\n","Frederic S. Mishkin (Labor Share: 41.20%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.3591 (35.91%)\n","  Hiring                   : 0.0230 (2.30%)\n","  Layoffs                  : 0.0031 (0.31%)\n","  Participation            : 0.0347 (3.47%)\n","  Unemployment             : 0.1383 (13.83%)\n","  Vacancies                : 0.0106 (1.06%)\n","  Wages                    : 0.3572 (35.72%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.1328 (13.28%)\n","  Core                     : 0.0707 (7.07%)\n","  Core_CPI                 : 0.0085 (0.85%)\n","  Core_PCE                 : 0.0065 (0.65%)\n","  Energy                   : 0.0609 (6.09%)\n","  Food                     : 0.0068 (0.68%)\n","  Goods                    : 0.0056 (0.56%)\n","  Headline                 : 0.0444 (4.44%)\n","  Headline_CPI             : 0.0222 (2.22%)\n","  Headline_PCE             : 0.0240 (2.40%)\n","  Housing                  : 0.0780 (7.80%)\n","  Inflation_Expectations   : 0.3080 (30.80%)\n","  Wage_Inflation           : 0.0094 (0.94%)\n","\n","Kevin M. Warsh (Labor Share: 36.29%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.1970 (19.70%)\n","  Hiring                   : 0.0455 (4.55%)\n","  Layoffs                  : 0.0909 (9.09%)\n","  Participation            : 0.1061 (10.61%)\n","  Unemployment             : 0.1023 (10.23%)\n","  Wages                    : 0.1856 (18.56%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.1339 (13.39%)\n","  Core                     : 0.1401 (14.01%)\n","  Energy                   : 0.0719 (7.19%)\n","  Food                     : 0.0083 (0.83%)\n","  Headline                 : 0.0196 (1.96%)\n","  Headline_CPI             : 0.0312 (3.12%)\n","  Housing                  : 0.1023 (10.23%)\n","  Inflation_Expectations   : 0.2118 (21.18%)\n","  Wage_Inflation           : 0.0083 (0.83%)\n","\n","Donald L. Kohn (Labor Share: 33.61%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.1509 (15.09%)\n","  Hiring                   : 0.1079 (10.79%)\n","  Layoffs                  : 0.0119 (1.19%)\n","  Participation            : 0.0804 (8.04%)\n","  Unemployment             : 0.1433 (14.33%)\n","  Vacancies                : 0.0225 (2.25%)\n","  Wages                    : 0.3065 (30.65%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.1111 (11.11%)\n","  Core                     : 0.0385 (3.85%)\n","  Core_CPI                 : 0.0152 (1.52%)\n","  Core_PCE                 : 0.0056 (0.56%)\n","  Energy                   : 0.0807 (8.07%)\n","  Food                     : 0.0165 (1.65%)\n","  Goods                    : 0.0346 (3.46%)\n","  Headline                 : 0.0370 (3.70%)\n","  Headline_CPI             : 0.0292 (2.92%)\n","  Headline_PCE             : 0.0155 (1.55%)\n","  Housing                  : 0.0672 (6.72%)\n","  Inflation_Expectations   : 0.1425 (14.25%)\n","  Wage_Inflation           : 0.0536 (5.36%)\n","\n","Roger W. Ferguson Jr. (Labor Share: 25.05%)\n","----------------------------------------------------------------------\n","Labor Emphasis:\n","  Employment               : 0.0661 (6.61%)\n","  Hiring                   : 0.0476 (4.76%)\n","  Participation            : 0.1389 (13.89%)\n","  Unemployment             : 0.0847 (8.47%)\n","  Vacancies                : 0.0238 (2.38%)\n","  Wages                    : 0.3056 (30.56%)\n","\n","Inflation Emphasis:\n","  Commodity_Prices         : 0.3040 (30.40%)\n","  Core                     : 0.0258 (2.58%)\n","  Energy                   : 0.0563 (5.63%)\n","  Headline                 : 0.0023 (0.23%)\n","  Headline_CPI             : 0.0023 (0.23%)\n","  Housing                  : 0.0880 (8.80%)\n","  Inflation_Expectations   : 0.0211 (2.11%)\n","\n","Total sentences extracted: 105535\n","\n","Classification distribution:\n","classification\n","Neither      89637\n","Labor         8390\n","Inflation     5835\n","Both          1673\n","Name: count, dtype: int64\n","\n","Sampling sentences for validation...\n","\n","Validation set created: /content/drive/MyDrive/FedComs/Validation_Sets/speeches_validate.csv\n","Total sentences in validation set: 45\n","\n","Validation set distribution:\n","classification\n","Inflation    15\n","Labor        15\n","Neither      10\n","Both          5\n","Name: count, dtype: int64\n","\n","======================================================================\n","SAMPLE VALIDATION SENTENCES (10 examples)\n","======================================================================\n","\n","[1] Classification: Neither\n","    Official: Randal K. Quarles\n","    Sentence: However, as you can likely surmise, he had to attend to other matters and asked me to speak in his place.\n","\n","[2] Classification: Inflation\n","    Official: Lael Brainard\n","    Inflation Indicators: Inflation_Expectations\n","    Sentence: To the extent that the persistent components of these nonhousing services and core goods reflect common factors that are fading, such as pass-through from commodity and supply chain shocks, they are u...\n","\n","[3] Classification: Neither\n","    Official: Lael Brainard\n","    Sentence: Here, as elsewhere in the country, there remain important gaps in economic opportunity.\n","\n","[4] Classification: Labor\n","    Official: Christopher J. Waller\n","    Labor Indicators: Vacancies\n","    Sentence: The number of job vacancies, a sign of strength in the labor market, has fallen gradually since the beginning of the year.\n","\n","[5] Classification: Labor\n","    Official: Michelle W. Bowman\n","    Sentence: It is crucial that U.S. official data accurately capture cyclical or structural changes in the labor market in real time so that we can more confidently rely on these data for monetary and economic po...\n","\n","[6] Classification: Both\n","    Official: Frederic S. Mishkin\n","    Labor Indicators: Employment\n","    Sentence: As a result, the public and the Congress can better assess whether our forecasts of the economy are reasonable and whether we are pursuing a policy that is consistent with achieving the dual mandate o...\n","\n","[7] Classification: Labor\n","    Official: Lael Brainard\n","    Labor Indicators: Unemployment\n","    Sentence: Our Review With recent indicators suggesting the expansion is continuing at a solid pace and unemployment at a 50-year low, inflation has not yet moved to our goal on a sustained basis.\n","\n","[8] Classification: Both\n","    Official: Christopher J. Waller\n","    Labor Indicators: Employment, Wages\n","    Inflation Indicators: Wage_Inflation\n","    Sentence: Wages continue to grow quickly on a more sustained basis than they have in more than 20 years, most recently reflected in a striking increase in the employment cost index, which considers both pay and...\n","\n","[9] Classification: Labor\n","    Official: Ben S. Bernanke\n","    Labor Indicators: Unemployment\n","    Sentence: Over time, we added long-run projections of inflation, growth, and unemployment, as well as projections of the path of the target federal funds rate consistent with each individual's views of appropri...\n","\n","[10] Classification: Labor\n","    Official: Richard H. Clarida\n","    Labor Indicators: Unemployment\n","    Sentence: Likewise, although unemployment rates for less-educated workers are persistently higher than they are for their more-educated counterparts, such gaps appear to narrow as the labor market strengthens.\n","\n","======================================================================\n","PROCESSING COMPLETE!\n","======================================================================\n"]}]}]}