{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZmA57zwfIVTX175YeDxQ7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\"\n","Combine Fed Communications Data\n","Combines minutes, statements, transcripts, speeches, and press conferences\n","into a single dataset with standardized variables.\n","\"\"\"\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import os\n","\n","# ============================================================================\n","# CONFIGURATION\n","# ============================================================================\n","\n","BASE_DIR = '/content/drive/MyDrive/FedComs'\n","OUTPUT_DIR = f'{BASE_DIR}/SummaryStats'\n","\n","# Input files\n","INPUT_FILES = {\n","    'minutes': f'{BASE_DIR}/Minutes/minutes_content.csv',\n","    'statements': f'{BASE_DIR}/Statements/statement_content.csv',\n","    'transcripts': f'{BASE_DIR}/Transcripts/transcripts_content.csv',\n","    'speeches': f'{BASE_DIR}/Speeches/speeches_content.csv',\n","    'presscon': f'{BASE_DIR}/PressConf/press_conferences_content.csv'\n","}\n","\n","# ============================================================================\n","# SPEAKER NAME STANDARDIZATION\n","# ============================================================================\n","\n","def standardize_speaker_name(name):\n","    \"\"\"\n","    Convert full names to format: firstinitiallastname (e.g., 'jpowell')\n","    Handle various name formats and return '.' for missing values.\n","    \"\"\"\n","    if pd.isna(name) or name == '' or str(name).strip() == '':\n","        return '.'\n","\n","    name = str(name).strip()\n","\n","    # Handle special cases\n","    if name.lower() in ['other', 'fomc', '.']:\n","        return name.lower() if name.lower() != '.' else '.'\n","\n","    # Remove common titles and suffixes\n","    name = name.replace('Jr.', '').replace('Jr', '').replace('Sr.', '').replace('Sr', '')\n","    name = name.replace('Dr.', '').replace('Dr', '').replace('Mr.', '').replace('Ms.', '')\n","\n","    # Split name into parts\n","    parts = name.split()\n","\n","    if len(parts) == 0:\n","        return '.'\n","    elif len(parts) == 1:\n","        # Just last name\n","        return parts[0].lower()\n","    else:\n","        # First initial + last name\n","        first_initial = parts[0][0].lower()\n","        last_name = parts[-1].lower()\n","        return f\"{first_initial}{last_name}\"\n","\n","# ============================================================================\n","# INSTITUTION AND PRESIDENT MAPPINGS\n","# ============================================================================\n","\n","# Regional bank mapping\n","REGIONAL_BANKS = {\n","    'boston': 'Boston',\n","    'new york': 'New York',\n","    'philadelphia': 'Philadelphia',\n","    'cleveland': 'Cleveland',\n","    'richmond': 'Richmond',\n","    'atlanta': 'Atlanta',\n","    'chicago': 'Chicago',\n","    'st. louis': 'St. Louis',\n","    'minneapolis': 'Minneapolis',\n","    'kansas city': 'Kansas City',\n","    'dallas': 'Dallas',\n","    'san francisco': 'San Francisco'\n","}\n","\n","# President who appointed each Fed official (Board members only)\n","# Format: standardized_name: (president, start_year, end_year)\n","APPOINTING_PRESIDENT = {\n","    # Chairs\n","    'agreenspan': ('Reagan', 1987, 2006),\n","    'bbernanke': ('Bush', 2006, 2014),\n","    'jyellen': ('Obama', 2014, 2018),\n","    'jpowell': ('Trump', 2018, None),\n","\n","    # Governors (major ones from 2000-present)\n","    'sbies': ('Clinton', 2001, 2007),\n","    'rjr': ('Clinton', 1997, 2006),  # Roger Ferguson\n","    'rferguson': ('Clinton', 1997, 2006),\n","    'molson': ('Clinton', 2001, 2006),\n","    'swarsh': ('Clinton', 1997, 2002),\n","    'egramlich': ('Clinton', 1997, 2005),\n","    'lmeyer': ('Clinton', 1996, 2002),\n","    'eguernsey': ('Bush', 2006, 2008),\n","    'rkreszner': ('Bush', 2006, 2009),\n","    'kmishkin': ('Bush', 2006, 2008),\n","    'fmishkin': ('Bush', 2006, 2008),\n","    'kwarsh': ('Bush', 2006, 2011),\n","    'dkohn': ('Clinton', 2002, 2010),\n","    'etarullo': ('Obama', 2009, 2017),\n","    'dduke': ('Obama', 2008, 2013),\n","    'sraskin': ('Obama', 2010, 2014),\n","    'jstein': ('Obama', 2012, 2014),\n","    'jyellen': ('Obama', 2010, 2018),  # Also as Governor before Chair\n","    'jpowell': ('Obama', 2012, None),  # Also as Governor before Chair\n","    'lbrainard': ('Obama', 2014, 2024),\n","    'rquarles': ('Trump', 2017, 2022),\n","    'mbowman': ('Trump', 2018, None),\n","    'rquarles': ('Trump', 2017, 2022),\n","    'mclarida': ('Trump', 2018, 2022),\n","    'cwaller': ('Trump', 2020, None),\n","    'ljefferson': ('Biden', 2022, None),\n","    'pcook': ('Biden', 2022, None),\n","    'mkugler': ('Biden', 2023, None),\n","    'abarr': ('Biden', 2022, None),\n","\n","    # Add more as needed - this covers most major officials 2000-2025\n","}\n","\n","# ============================================================================\n","# ROLE DETERMINATION\n","# ============================================================================\n","\n","def determine_role(speaker, role_field, date, com_type):\n","    \"\"\"\n","    Determine role: Chair, Governor, Regional President, FOMC, or Other\n","    \"\"\"\n","    # For statements and minutes, always FOMC\n","    if com_type in ['statements', 'minutes']:\n","        return 'FOMC'\n","\n","    # For press conferences with \"Other\"\n","    if com_type == 'presscon' and speaker == 'other':\n","        return 'Other'\n","\n","    # If role field exists, use it\n","    if pd.notna(role_field) and role_field != '':\n","        role_str = str(role_field).strip()\n","\n","        # Check for Chair\n","        if 'chair' in role_str.lower() and 'vice' not in role_str.lower():\n","            return 'Chair'\n","\n","        # Check for Governor (including Vice Chair)\n","        if 'governor' in role_str.lower() or 'vice chair' in role_str.lower():\n","            return 'Governor'\n","\n","        # Regional banks\n","        if any(bank in role_str.lower() for bank in REGIONAL_BANKS.keys()):\n","            return 'Regional President'\n","\n","    # Fallback: determine chair by date if speaker is standardized chair name\n","    if pd.notna(date):\n","        try:\n","            date_obj = pd.to_datetime(date)\n","\n","            # Known Fed Chairs and their tenures\n","            if speaker in ['agreenspan', 'greenspan']:\n","                if date_obj < pd.to_datetime('2006-02-01'):\n","                    return 'Chair'\n","            elif speaker in ['bbernanke', 'bernanke']:\n","                if pd.to_datetime('2006-02-01') <= date_obj < pd.to_datetime('2014-02-01'):\n","                    return 'Chair'\n","            elif speaker in ['jyellen', 'yellen']:\n","                if pd.to_datetime('2014-02-01') <= date_obj < pd.to_datetime('2018-02-05'):\n","                    return 'Chair'\n","            elif speaker in ['jpowell', 'powell']:\n","                if date_obj >= pd.to_datetime('2018-02-05'):\n","                    return 'Chair'\n","        except:\n","            pass\n","\n","    return '.'\n","\n","def determine_institution(speaker, role_field, role):\n","    \"\"\"\n","    Determine institution: Board or specific Regional Bank\n","    Returns '.' for FOMC, Other, or missing data\n","    \"\"\"\n","    # No institution for FOMC or Other\n","    if role in ['FOMC', 'Other'] or speaker in ['fomc', 'other', '.']:\n","        return '.'\n","\n","    # Board members (Chair and Governors)\n","    if role in ['Chair', 'Governor']:\n","        return 'Board'\n","\n","    # Regional Presidents - extract from role field\n","    if pd.notna(role_field) and role_field != '':\n","        role_str = str(role_field).strip().lower()\n","        for bank_key, bank_name in REGIONAL_BANKS.items():\n","            if bank_key in role_str:\n","                return bank_name\n","\n","    return '.'\n","\n","def determine_appointing_president(speaker, date, role):\n","    \"\"\"\n","    Determine which president appointed the official (Board members only)\n","    Returns '.' for non-Board members or unknown\n","    \"\"\"\n","    # Only for Board members\n","    if role not in ['Chair', 'Governor']:\n","        return '.'\n","\n","    if speaker in ['.', 'fomc', 'other']:\n","        return '.'\n","\n","    # Look up in mapping\n","    if speaker in APPOINTING_PRESIDENT:\n","        pres_info = APPOINTING_PRESIDENT[speaker]\n","        president = pres_info[0]\n","\n","        # Verify date is within tenure (if date available)\n","        if pd.notna(date):\n","            try:\n","                date_obj = pd.to_datetime(date)\n","                year = date_obj.year\n","\n","                start_year = pres_info[1]\n","                end_year = pres_info[2]\n","\n","                # Check if date is within tenure\n","                if end_year is None:  # Still serving\n","                    if year >= start_year:\n","                        return president\n","                else:\n","                    if start_year <= year <= end_year:\n","                        return president\n","            except:\n","                pass\n","\n","        # If no date validation, just return the president\n","        return president\n","\n","    return '.'\n","\n","# ============================================================================\n","# DATE PROCESSING\n","# ============================================================================\n","\n","def process_date(date_val):\n","    \"\"\"\n","    Convert date to standard format and extract year/month.\n","    Returns: (formatted_date, year, month) or ('.', '.', '.') if invalid\n","    \"\"\"\n","    if pd.isna(date_val) or date_val == '' or str(date_val).strip() == '':\n","        return '.', '.', '.'\n","\n","    try:\n","        # Parse date\n","        date_obj = pd.to_datetime(date_val, errors='coerce')\n","\n","        if pd.isna(date_obj):\n","            return '.', '.', '.'\n","\n","        # Format as YYYY-MM-DD\n","        formatted_date = date_obj.strftime('%Y-%m-%d')\n","        year = str(date_obj.year)\n","        month = str(date_obj.month)\n","\n","        return formatted_date, year, month\n","    except:\n","        return '.', '.', '.'\n","\n","# ============================================================================\n","# CONTENT VARIABLES - Define the 77 variables we want to keep\n","# ============================================================================\n","\n","CONTENT_VARS = [\n","    'source_url',\n","    'sentences_on_labor',\n","    'sentences_on_inflation',\n","    'sentences_on_both',\n","    'total_sentences',\n","    'labor_share_of_labor_inflation_sentences',\n","    # Labor counts\n","    'labor_Employment_count',\n","    'labor_Unemployment_count',\n","    'labor_Participation_count',\n","    'labor_Wages_count',\n","    'labor_Vacancies_count',\n","    'labor_Quits_count',\n","    'labor_Layoffs_count',\n","    'labor_Hiring_count',\n","    # Inflation counts\n","    'inflation_Commodity_Prices_count',\n","    'inflation_Core_count',\n","    'inflation_Core_CPI_count',\n","    'inflation_Core_PCE_count',\n","    'inflation_Energy_count',\n","    'inflation_Food_count',\n","    'inflation_Goods_count',\n","    'inflation_Headline_count',\n","    'inflation_Headline_CPI_count',\n","    'inflation_Headline_PCE_count',\n","    'inflation_Housing_count',\n","    'inflation_Inflation_Expectations_count',\n","    'inflation_PPI_count',\n","    'inflation_Services_count',\n","    'inflation_Wage_Inflation_count',\n","    # Labor emphasis\n","    'labor_emphasis_Employment',\n","    'labor_emphasis_Unemployment',\n","    'labor_emphasis_Participation',\n","    'labor_emphasis_Wages',\n","    'labor_emphasis_Vacancies',\n","    'labor_emphasis_Quits',\n","    'labor_emphasis_Layoffs',\n","    'labor_emphasis_Hiring',\n","    # Inflation emphasis\n","    'inflation_emphasis_Commodity_Prices',\n","    'inflation_emphasis_Core',\n","    'inflation_emphasis_Core_CPI',\n","    'inflation_emphasis_Core_PCE',\n","    'inflation_emphasis_Energy',\n","    'inflation_emphasis_Food',\n","    'inflation_emphasis_Goods',\n","    'inflation_emphasis_Headline',\n","    'inflation_emphasis_Headline_CPI',\n","    'inflation_emphasis_Headline_PCE',\n","    'inflation_emphasis_Housing',\n","    'inflation_emphasis_Inflation_Expectations',\n","    'inflation_emphasis_PPI',\n","    'inflation_emphasis_Services',\n","    'inflation_emphasis_Wage_Inflation',\n","    # Labor share of total sentences\n","    'labor_share_total_sentences_Employment',\n","    'labor_share_total_sentences_Unemployment',\n","    'labor_share_total_sentences_Participation',\n","    'labor_share_total_sentences_Wages',\n","    'labor_share_total_sentences_Vacancies',\n","    'labor_share_total_sentences_Quits',\n","    'labor_share_total_sentences_Layoffs',\n","    'labor_share_total_sentences_Hiring',\n","    # Inflation share of total sentences\n","    'inflation_share_total_sentences_Commodity_Prices',\n","    'inflation_share_total_sentences_Core',\n","    'inflation_share_total_sentences_Core_CPI',\n","    'inflation_share_total_sentences_Core_PCE',\n","    'inflation_share_total_sentences_Energy',\n","    'inflation_share_total_sentences_Food',\n","    'inflation_share_total_sentences_Goods',\n","    'inflation_share_total_sentences_Headline',\n","    'inflation_share_total_sentences_Headline_CPI',\n","    'inflation_share_total_sentences_Headline_PCE',\n","    'inflation_share_total_sentences_Housing',\n","    'inflation_share_total_sentences_Inflation_Expectations',\n","    'inflation_share_total_sentences_PPI',\n","    'inflation_share_total_sentences_Services',\n","    'inflation_share_total_sentences_Wage_Inflation'\n","]\n","\n","# ============================================================================\n","# PROCESS EACH DATA SOURCE\n","# ============================================================================\n","\n","def process_minutes(filepath):\n","    \"\"\"Process FOMC minutes.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: MINUTES\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Create standardized columns\n","    df['com_type'] = 'minutes'\n","    df['speaker'] = 'fomc'\n","    df['role'] = 'FOMC'\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Add institution and president (blank for FOMC)\n","    df['institution'] = '.'\n","    df['president'] = '.'\n","\n","    # Get source file name\n","    df['source_file'] = 'minutes_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'institution', 'president',\n","                 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_statements(filepath):\n","    \"\"\"Process FOMC statements.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: STATEMENTS\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Create standardized columns\n","    df['com_type'] = 'statements'\n","    df['speaker'] = 'fomc'\n","    df['role'] = 'FOMC'\n","    df['source_url'] = '.'  # Statements don't have source_url\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Add institution and president (blank for FOMC)\n","    df['institution'] = '.'\n","    df['president'] = '.'\n","\n","    # Get source file name\n","    df['source_file'] = 'statement_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'institution', 'president',\n","                 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_transcripts(filepath):\n","    \"\"\"Process FOMC transcripts.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: TRANSCRIPTS\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Standardize speaker names\n","    df['speaker'] = df['official_name'].apply(standardize_speaker_name)\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Store original role field for institution determination\n","    df['role_original'] = df['role']\n","\n","    # Determine roles\n","    df['role'] = df.apply(\n","        lambda row: determine_role(row['speaker'], row['role_original'], row['date'], 'transcripts'),\n","        axis=1\n","    )\n","\n","    # Determine institution\n","    df['institution'] = df.apply(\n","        lambda row: determine_institution(row['speaker'], row['role_original'], row['role']),\n","        axis=1\n","    )\n","\n","    # Determine appointing president\n","    df['president'] = df.apply(\n","        lambda row: determine_appointing_president(row['speaker'], row['date'], row['role']),\n","        axis=1\n","    )\n","\n","    # Rename id column\n","    df = df.rename(columns={'transcript_id': 'id'})\n","\n","    # Create standardized columns\n","    df['com_type'] = 'transcripts'\n","    df['source_url'] = '.'  # Transcripts don't have source_url\n","    df['source_file'] = 'transcripts_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'institution', 'president',\n","                 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_speeches(filepath):\n","    \"\"\"Process Fed speeches.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: SPEECHES\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Standardize speaker names (already have 'speaker' column)\n","    df['speaker'] = df['speaker'].apply(standardize_speaker_name)\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Store original role field for institution determination\n","    df['role_original'] = df['role']\n","\n","    # Determine roles\n","    df['role'] = df.apply(\n","        lambda row: determine_role(row['speaker'], row['role_original'], row['date'], 'speeches'),\n","        axis=1\n","    )\n","\n","    # Determine institution\n","    df['institution'] = df.apply(\n","        lambda row: determine_institution(row['speaker'], row['role_original'], row['role']),\n","        axis=1\n","    )\n","\n","    # Determine appointing president\n","    df['president'] = df.apply(\n","        lambda row: determine_appointing_president(row['speaker'], row['date'], row['role']),\n","        axis=1\n","    )\n","\n","    # Rename url to source_url\n","    df = df.rename(columns={'url': 'source_url'})\n","\n","    # Create standardized columns\n","    df['com_type'] = 'speeches'\n","    df['source_file'] = 'speeches_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'institution', 'president',\n","                 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_press_conferences(filepath):\n","    \"\"\"Process press conferences.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: PRESS CONFERENCES\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Standardize speaker names\n","    df['speaker'] = df['speaker'].apply(standardize_speaker_name)\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Determine roles\n","    df['role'] = df.apply(\n","        lambda row: determine_role(row['speaker'], None, row['date'], 'presscon'),\n","        axis=1\n","    )\n","\n","    # Determine institution (Board for Chair, blank for Other)\n","    df['institution'] = df.apply(\n","        lambda row: 'Board' if row['role'] == 'Chair' else '.',\n","        axis=1\n","    )\n","\n","    # Determine appointing president\n","    df['president'] = df.apply(\n","        lambda row: determine_appointing_president(row['speaker'], row['date'], row['role']),\n","        axis=1\n","    )\n","\n","    # Rename id column\n","    df = df.rename(columns={'press_conf_id': 'id'})\n","\n","    # Create standardized columns\n","    df['com_type'] = 'presscon'\n","    df['source_file'] = 'press_conferences_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'institution', 'president',\n","                 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","# ============================================================================\n","# MAIN EXECUTION\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"COMBINING FED COMMUNICATIONS DATA\")\n","print(\"=\"*70)\n","\n","# Create output directory if it doesn't exist\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Process each source\n","dfs = []\n","\n","if os.path.exists(INPUT_FILES['minutes']):\n","    dfs.append(process_minutes(INPUT_FILES['minutes']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['minutes']} not found\")\n","\n","if os.path.exists(INPUT_FILES['statements']):\n","    dfs.append(process_statements(INPUT_FILES['statements']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['statements']} not found\")\n","\n","if os.path.exists(INPUT_FILES['transcripts']):\n","    dfs.append(process_transcripts(INPUT_FILES['transcripts']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['transcripts']} not found\")\n","\n","if os.path.exists(INPUT_FILES['speeches']):\n","    dfs.append(process_speeches(INPUT_FILES['speeches']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['speeches']} not found\")\n","\n","if os.path.exists(INPUT_FILES['presscon']):\n","    dfs.append(process_press_conferences(INPUT_FILES['presscon']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['presscon']} not found\")\n","\n","# Combine all dataframes\n","print(\"\\n\" + \"=\"*70)\n","print(\"COMBINING ALL SOURCES\")\n","print(\"=\"*70)\n","\n","if len(dfs) > 0:\n","    combined_df = pd.concat(dfs, ignore_index=True)\n","\n","    # Sort by date\n","    combined_df['date_sort'] = pd.to_datetime(combined_df['date'], errors='coerce')\n","    combined_df = combined_df.sort_values('date_sort')\n","    combined_df = combined_df.drop('date_sort', axis=1)\n","\n","    # Save combined dataset\n","    output_file = os.path.join(OUTPUT_DIR, 'Combined_Dataset.csv')\n","    combined_df.to_csv(output_file, index=False)\n","\n","    print(f\"\\n✓ Combined dataset saved to: {output_file}\")\n","    print(f\"  Total records: {len(combined_df)}\")\n","    print(f\"  Shape: {combined_df.shape}\")\n","    print(f\"\\n  Records by communication type:\")\n","    print(combined_df['com_type'].value_counts().to_string())\n","    print(f\"\\n  Records by role:\")\n","    print(combined_df['role'].value_counts().to_string())\n","    print(f\"\\n  Date range: {combined_df['date'].min()} to {combined_df['date'].max()}\")\n","\n","    # Display first few rows\n","    print(f\"\\n  Sample of first 5 rows:\")\n","    print(combined_df[['id', 'com_type', 'speaker', 'role', 'institution', 'president',\n","                       'date', 'year', 'month']].head())\n","\n","else:\n","    print(\"\\nError: No data files found!\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"PROCESSING COMPLETE!\")\n","print(\"=\"*70)"],"metadata":{"id":"zj1sOQIvWEDt","executionInfo":{"status":"ok","timestamp":1761663811836,"user_tz":300,"elapsed":7844,"user":{"displayName":"Amanda Michaud","userId":"14525267344116117436"}},"outputId":"9c59af0e-4f74-46f6-a4e3-d9d8d82e9fdc","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","======================================================================\n","COMBINING FED COMMUNICATIONS DATA\n","======================================================================\n","\n","======================================================================\n","PROCESSING: MINUTES\n","======================================================================\n","Loaded 199 records\n","\n","======================================================================\n","PROCESSING: STATEMENTS\n","======================================================================\n","Loaded 198 records\n","\n","======================================================================\n","PROCESSING: TRANSCRIPTS\n","======================================================================\n","Loaded 2589 records\n","\n","======================================================================\n","PROCESSING: SPEECHES\n","======================================================================\n","Loaded 1121 records\n","\n","======================================================================\n","PROCESSING: PRESS CONFERENCES\n","======================================================================\n","Loaded 170 records\n","\n","======================================================================\n","COMBINING ALL SOURCES\n","======================================================================\n","\n","✓ Combined dataset saved to: /content/drive/MyDrive/FedComs/SummaryStats/Combined_Dataset.csv\n","  Total records: 4277\n","  Shape: (4277, 85)\n","\n","  Records by communication type:\n","com_type\n","transcripts    2589\n","speeches       1121\n","minutes         199\n","statements      198\n","presscon        170\n","\n","  Records by role:\n","role\n","Regional President    1771\n","Governor              1548\n","Chair                  475\n","FOMC                   397\n","Other                   85\n",".                        1\n","\n","  Date range: 2000-02-02 to 2025-09-23\n","\n","  Sample of first 5 rows:\n","                                 id     com_type     speaker  \\\n","0                  minutes_20000202      minutes        fomc   \n","397     EBoehne_20000202_transcript  transcripts     eboehne   \n","398      RParry_20000202_transcript  transcripts      rparry   \n","399     MMoskow_20000202_transcript  transcripts     mmoskow   \n","400  AGreenspan_20000202_transcript  transcripts  agreenspan   \n","\n","                   role    institution president        date  year month  \n","0                  FOMC              .         .  2000-02-02  2000     2  \n","397  Regional President   Philadelphia         .  2000-02-02  2000     2  \n","398  Regional President  San Francisco         .  2000-02-02  2000     2  \n","399  Regional President        Chicago         .  2000-02-02  2000     2  \n","400               Chair          Board    Reagan  2000-02-02  2000     2  \n","\n","======================================================================\n","PROCESSING COMPLETE!\n","======================================================================\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Combine Fed Communications Data\n","Combines minutes, statements, transcripts, speeches, and press conferences\n","into a single dataset with standardized variables.\n","\"\"\"\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import os\n","\n","# ============================================================================\n","# CONFIGURATION\n","# ============================================================================\n","\n","BASE_DIR = '/content/drive/MyDrive/FedComs'\n","OUTPUT_DIR = f'{BASE_DIR}/SummaryStats'\n","\n","# Input files\n","INPUT_FILES = {\n","    'minutes': f'{BASE_DIR}/Minutes/minutes_content.csv',\n","    'statements': f'{BASE_DIR}/Statements/statement_content.csv',\n","    'transcripts': f'{BASE_DIR}/Transcripts/transcripts_content.csv',\n","    'speeches': f'{BASE_DIR}/Speeches/speeches_content.csv',\n","    'presscon': f'{BASE_DIR}/PressConf/press_conferences_content.csv'\n","}\n","\n","# ============================================================================\n","# SPEAKER NAME STANDARDIZATION\n","# ============================================================================\n","\n","def standardize_speaker_name(name):\n","    \"\"\"\n","    Convert full names to format: firstinitiallastname (e.g., 'jpowell')\n","    Handle various name formats and return '.' for missing values.\n","    \"\"\"\n","    if pd.isna(name) or name == '' or str(name).strip() == '':\n","        return '.'\n","\n","    name = str(name).strip()\n","\n","    # Handle special cases\n","    if name.lower() in ['other', 'fomc', '.']:\n","        return name.lower() if name.lower() != '.' else '.'\n","\n","    # Remove common titles and suffixes\n","    name = name.replace('Jr.', '').replace('Jr', '').replace('Sr.', '').replace('Sr', '')\n","    name = name.replace('Dr.', '').replace('Dr', '').replace('Mr.', '').replace('Ms.', '')\n","\n","    # Split name into parts\n","    parts = name.split()\n","\n","    if len(parts) == 0:\n","        return '.'\n","    elif len(parts) == 1:\n","        # Just last name\n","        return parts[0].lower()\n","    else:\n","        # First initial + last name\n","        first_initial = parts[0][0].lower()\n","        last_name = parts[-1].lower()\n","        return f\"{first_initial}{last_name}\"\n","\n","# ============================================================================\n","# ROLE DETERMINATION\n","# ============================================================================\n","\n","def determine_role(speaker, role_field, date, com_type):\n","    \"\"\"\n","    Determine role: Chair, Governor, Regional President, FOMC, or Other\n","    \"\"\"\n","    # For statements and minutes, always FOMC\n","    if com_type in ['statements', 'minutes']:\n","        return 'FOMC'\n","\n","    # For press conferences with \"Other\"\n","    if com_type == 'presscon' and speaker == 'other':\n","        return 'Other'\n","\n","    # If role field exists, use it\n","    if pd.notna(role_field) and role_field != '':\n","        role_str = str(role_field).strip()\n","\n","        # Check for Chair\n","        if 'chair' in role_str.lower() and 'vice' not in role_str.lower():\n","            return 'Chair'\n","\n","        # Check for Governor (including Vice Chair)\n","        if 'governor' in role_str.lower() or 'vice chair' in role_str.lower():\n","            return 'Governor'\n","\n","        # Regional banks\n","        regional_banks = [\n","            'boston', 'new york', 'philadelphia', 'cleveland', 'richmond',\n","            'atlanta', 'chicago', 'st. louis', 'minneapolis', 'kansas city',\n","            'dallas', 'san francisco'\n","        ]\n","\n","        if any(bank in role_str.lower() for bank in regional_banks):\n","            return 'Regional President'\n","\n","    # Fallback: determine chair by date if speaker is standardized chair name\n","    if pd.notna(date):\n","        try:\n","            date_obj = pd.to_datetime(date)\n","\n","            # Known Fed Chairs and their tenures\n","            if speaker in ['agreenspan', 'greenspan']:\n","                if date_obj < pd.to_datetime('2006-02-01'):\n","                    return 'Chair'\n","            elif speaker in ['bbernanke', 'bernanke']:\n","                if pd.to_datetime('2006-02-01') <= date_obj < pd.to_datetime('2014-02-01'):\n","                    return 'Chair'\n","            elif speaker in ['jyellen', 'yellen']:\n","                if pd.to_datetime('2014-02-01') <= date_obj < pd.to_datetime('2018-02-05'):\n","                    return 'Chair'\n","            elif speaker in ['jpowell', 'powell']:\n","                if date_obj >= pd.to_datetime('2018-02-05'):\n","                    return 'Chair'\n","        except:\n","            pass\n","\n","    return '.'\n","\n","# ============================================================================\n","# DATE PROCESSING\n","# ============================================================================\n","\n","def process_date(date_val):\n","    \"\"\"\n","    Convert date to standard format and extract year/month.\n","    Returns: (formatted_date, year, month) or ('.', '.', '.') if invalid\n","    \"\"\"\n","    if pd.isna(date_val) or date_val == '' or str(date_val).strip() == '':\n","        return '.', '.', '.'\n","\n","    try:\n","        # Parse date\n","        date_obj = pd.to_datetime(date_val, errors='coerce')\n","\n","        if pd.isna(date_obj):\n","            return '.', '.', '.'\n","\n","        # Format as YYYY-MM-DD\n","        formatted_date = date_obj.strftime('%Y-%m-%d')\n","        year = str(date_obj.year)\n","        month = str(date_obj.month)\n","\n","        return formatted_date, year, month\n","    except:\n","        return '.', '.', '.'\n","\n","# ============================================================================\n","# CONTENT VARIABLES - Define the 77 variables we want to keep\n","# ============================================================================\n","\n","CONTENT_VARS = [\n","    'source_url',\n","    'sentences_on_labor',\n","    'sentences_on_inflation',\n","    'sentences_on_both',\n","    'total_sentences',\n","    'labor_share_of_labor_inflation_sentences',\n","    # Labor counts\n","    'labor_Employment_count',\n","    'labor_Unemployment_count',\n","    'labor_Participation_count',\n","    'labor_Wages_count',\n","    'labor_Vacancies_count',\n","    'labor_Quits_count',\n","    'labor_Layoffs_count',\n","    'labor_Hiring_count',\n","    # Inflation counts\n","    'inflation_Commodity_Prices_count',\n","    'inflation_Core_count',\n","    'inflation_Core_CPI_count',\n","    'inflation_Core_PCE_count',\n","    'inflation_Energy_count',\n","    'inflation_Food_count',\n","    'inflation_Goods_count',\n","    'inflation_Headline_count',\n","    'inflation_Headline_CPI_count',\n","    'inflation_Headline_PCE_count',\n","    'inflation_Housing_count',\n","    'inflation_Inflation_Expectations_count',\n","    'inflation_PPI_count',\n","    'inflation_Services_count',\n","    'inflation_Wage_Inflation_count',\n","    # Labor emphasis\n","    'labor_emphasis_Employment',\n","    'labor_emphasis_Unemployment',\n","    'labor_emphasis_Participation',\n","    'labor_emphasis_Wages',\n","    'labor_emphasis_Vacancies',\n","    'labor_emphasis_Quits',\n","    'labor_emphasis_Layoffs',\n","    'labor_emphasis_Hiring',\n","    # Inflation emphasis\n","    'inflation_emphasis_Commodity_Prices',\n","    'inflation_emphasis_Core',\n","    'inflation_emphasis_Core_CPI',\n","    'inflation_emphasis_Core_PCE',\n","    'inflation_emphasis_Energy',\n","    'inflation_emphasis_Food',\n","    'inflation_emphasis_Goods',\n","    'inflation_emphasis_Headline',\n","    'inflation_emphasis_Headline_CPI',\n","    'inflation_emphasis_Headline_PCE',\n","    'inflation_emphasis_Housing',\n","    'inflation_emphasis_Inflation_Expectations',\n","    'inflation_emphasis_PPI',\n","    'inflation_emphasis_Services',\n","    'inflation_emphasis_Wage_Inflation',\n","    # Labor share of total sentences\n","    'labor_share_total_sentences_Employment',\n","    'labor_share_total_sentences_Unemployment',\n","    'labor_share_total_sentences_Participation',\n","    'labor_share_total_sentences_Wages',\n","    'labor_share_total_sentences_Vacancies',\n","    'labor_share_total_sentences_Quits',\n","    'labor_share_total_sentences_Layoffs',\n","    'labor_share_total_sentences_Hiring',\n","    # Inflation share of total sentences\n","    'inflation_share_total_sentences_Commodity_Prices',\n","    'inflation_share_total_sentences_Core',\n","    'inflation_share_total_sentences_Core_CPI',\n","    'inflation_share_total_sentences_Core_PCE',\n","    'inflation_share_total_sentences_Energy',\n","    'inflation_share_total_sentences_Food',\n","    'inflation_share_total_sentences_Goods',\n","    'inflation_share_total_sentences_Headline',\n","    'inflation_share_total_sentences_Headline_CPI',\n","    'inflation_share_total_sentences_Headline_PCE',\n","    'inflation_share_total_sentences_Housing',\n","    'inflation_share_total_sentences_Inflation_Expectations',\n","    'inflation_share_total_sentences_PPI',\n","    'inflation_share_total_sentences_Services',\n","    'inflation_share_total_sentences_Wage_Inflation'\n","]\n","\n","# ============================================================================\n","# PROCESS EACH DATA SOURCE\n","# ============================================================================\n","\n","def process_minutes(filepath):\n","    \"\"\"Process FOMC minutes.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: MINUTES\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Create standardized columns\n","    df['com_type'] = 'minutes'\n","    df['speaker'] = 'fomc'\n","    df['role'] = 'FOMC'\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Get source file name\n","    df['source_file'] = 'minutes_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_statements(filepath):\n","    \"\"\"Process FOMC statements.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: STATEMENTS\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Create standardized columns\n","    df['com_type'] = 'statements'\n","    df['speaker'] = 'fomc'\n","    df['role'] = 'FOMC'\n","    df['source_url'] = '.'  # Statements don't have source_url\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Get source file name\n","    df['source_file'] = 'statement_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_transcripts(filepath):\n","    \"\"\"Process FOMC transcripts.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: TRANSCRIPTS\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Standardize speaker names\n","    df['speaker'] = df['official_name'].apply(standardize_speaker_name)\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Determine roles\n","    df['role'] = df.apply(\n","        lambda row: determine_role(row['speaker'], row['role'], row['date'], 'transcripts'),\n","        axis=1\n","    )\n","\n","    # Rename id column\n","    df = df.rename(columns={'transcript_id': 'id'})\n","\n","    # Create standardized columns\n","    df['com_type'] = 'transcripts'\n","    df['source_url'] = '.'  # Transcripts don't have source_url\n","    df['source_file'] = 'transcripts_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_speeches(filepath):\n","    \"\"\"Process Fed speeches.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: SPEECHES\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Standardize speaker names (already have 'speaker' column)\n","    df['speaker'] = df['speaker'].apply(standardize_speaker_name)\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Determine roles\n","    df['role'] = df.apply(\n","        lambda row: determine_role(row['speaker'], row['role'], row['date'], 'speeches'),\n","        axis=1\n","    )\n","\n","    # Rename url to source_url\n","    df = df.rename(columns={'url': 'source_url'})\n","\n","    # Create standardized columns\n","    df['com_type'] = 'speeches'\n","    df['source_file'] = 'speeches_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","def process_press_conferences(filepath):\n","    \"\"\"Process press conferences.\"\"\"\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"PROCESSING: PRESS CONFERENCES\")\n","    print(\"=\"*70)\n","\n","    df = pd.read_csv(filepath)\n","    print(f\"Loaded {len(df)} records\")\n","\n","    # Standardize speaker names\n","    df['speaker'] = df['speaker'].apply(standardize_speaker_name)\n","\n","    # Process dates\n","    df[['date', 'year', 'month']] = df['date'].apply(\n","        lambda x: pd.Series(process_date(x))\n","    )\n","\n","    # Determine roles\n","    df['role'] = df.apply(\n","        lambda row: determine_role(row['speaker'], None, row['date'], 'presscon'),\n","        axis=1\n","    )\n","\n","    # Rename id column\n","    df = df.rename(columns={'press_conf_id': 'id'})\n","\n","    # Create standardized columns\n","    df['com_type'] = 'presscon'\n","    df['source_file'] = 'press_conferences_content.csv'\n","\n","    # Keep only needed columns\n","    keep_cols = ['id', 'com_type', 'speaker', 'role', 'date', 'year', 'month', 'source_file']\n","\n","    # Add content variables that exist\n","    for var in CONTENT_VARS:\n","        if var in df.columns:\n","            keep_cols.append(var)\n","        else:\n","            df[var] = '.'\n","            keep_cols.append(var)\n","\n","    return df[keep_cols]\n","\n","# ============================================================================\n","# MAIN EXECUTION\n","# ============================================================================\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"COMBINING FED COMMUNICATIONS DATA\")\n","print(\"=\"*70)\n","\n","# Create output directory if it doesn't exist\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Process each source\n","dfs = []\n","\n","if os.path.exists(INPUT_FILES['minutes']):\n","    dfs.append(process_minutes(INPUT_FILES['minutes']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['minutes']} not found\")\n","\n","if os.path.exists(INPUT_FILES['statements']):\n","    dfs.append(process_statements(INPUT_FILES['statements']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['statements']} not found\")\n","\n","if os.path.exists(INPUT_FILES['transcripts']):\n","    dfs.append(process_transcripts(INPUT_FILES['transcripts']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['transcripts']} not found\")\n","\n","if os.path.exists(INPUT_FILES['speeches']):\n","    dfs.append(process_speeches(INPUT_FILES['speeches']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['speeches']} not found\")\n","\n","if os.path.exists(INPUT_FILES['presscon']):\n","    dfs.append(process_press_conferences(INPUT_FILES['presscon']))\n","else:\n","    print(f\"\\nWarning: {INPUT_FILES['presscon']} not found\")\n","\n","# Combine all dataframes\n","print(\"\\n\" + \"=\"*70)\n","print(\"COMBINING ALL SOURCES\")\n","print(\"=\"*70)\n","\n","if len(dfs) > 0:\n","    combined_df = pd.concat(dfs, ignore_index=True)\n","\n","    # Sort by date\n","    combined_df['date_sort'] = pd.to_datetime(combined_df['date'], errors='coerce')\n","    combined_df = combined_df.sort_values('date_sort')\n","    combined_df = combined_df.drop('date_sort', axis=1)\n","\n","    # Save combined dataset\n","    output_file = os.path.join(OUTPUT_DIR, 'Combined_Dataset.csv')\n","    combined_df.to_csv(output_file, index=False)\n","\n","    print(f\"\\n✓ Combined dataset saved to: {output_file}\")\n","    print(f\"  Total records: {len(combined_df)}\")\n","    print(f\"  Shape: {combined_df.shape}\")\n","    print(f\"\\n  Records by communication type:\")\n","    print(combined_df['com_type'].value_counts().to_string())\n","    print(f\"\\n  Records by role:\")\n","    print(combined_df['role'].value_counts().to_string())\n","    print(f\"\\n  Date range: {combined_df['date'].min()} to {combined_df['date'].max()}\")\n","\n","    # Display first few rows\n","    print(f\"\\n  Sample of first 5 rows:\")\n","    print(combined_df[['id', 'com_type', 'speaker', 'role', 'date', 'year', 'month']].head())\n","\n","else:\n","    print(\"\\nError: No data files found!\")\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"PROCESSING COMPLETE!\")\n","print(\"=\"*70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rkv2LP7dUc3h","executionInfo":{"status":"ok","timestamp":1761663384622,"user_tz":300,"elapsed":9946,"user":{"displayName":"Amanda Michaud","userId":"14525267344116117436"}},"outputId":"9c950947-a019-4ace-84aa-617389a9c2c6"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","\n","======================================================================\n","COMBINING FED COMMUNICATIONS DATA\n","======================================================================\n","\n","======================================================================\n","PROCESSING: MINUTES\n","======================================================================\n","Loaded 199 records\n","\n","======================================================================\n","PROCESSING: STATEMENTS\n","======================================================================\n","Loaded 198 records\n","\n","======================================================================\n","PROCESSING: TRANSCRIPTS\n","======================================================================\n","Loaded 2589 records\n","\n","======================================================================\n","PROCESSING: SPEECHES\n","======================================================================\n","Loaded 1121 records\n","\n","======================================================================\n","PROCESSING: PRESS CONFERENCES\n","======================================================================\n","Loaded 170 records\n","\n","======================================================================\n","COMBINING ALL SOURCES\n","======================================================================\n","\n","✓ Combined dataset saved to: /content/drive/MyDrive/FedComs/SummaryStats/Combined_Dataset.csv\n","  Total records: 4277\n","  Shape: (4277, 83)\n","\n","  Records by communication type:\n","com_type\n","transcripts    2589\n","speeches       1121\n","minutes         199\n","statements      198\n","presscon        170\n","\n","  Records by role:\n","role\n","Regional President    1771\n","Governor              1548\n","Chair                  475\n","FOMC                   397\n","Other                   85\n",".                        1\n","\n","  Date range: 2000-02-02 to 2025-09-23\n","\n","  Sample of first 5 rows:\n","                                 id     com_type     speaker  \\\n","0                  minutes_20000202      minutes        fomc   \n","397     EBoehne_20000202_transcript  transcripts     eboehne   \n","398      RParry_20000202_transcript  transcripts      rparry   \n","399     MMoskow_20000202_transcript  transcripts     mmoskow   \n","400  AGreenspan_20000202_transcript  transcripts  agreenspan   \n","\n","                   role        date  year month  \n","0                  FOMC  2000-02-02  2000     2  \n","397  Regional President  2000-02-02  2000     2  \n","398  Regional President  2000-02-02  2000     2  \n","399  Regional President  2000-02-02  2000     2  \n","400               Chair  2000-02-02  2000     2  \n","\n","======================================================================\n","PROCESSING COMPLETE!\n","======================================================================\n"]}]}]}